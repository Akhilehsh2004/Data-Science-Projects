{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c80d10d5-272d-4f68-b1c0-50e02d0ac4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's listify the contents\n",
    "what_were_covering = [\n",
    "    \"0. An end-to-end Scikit-Learn workflow\",\n",
    "    \"1. Getting the data ready\",\n",
    "    \"2. Choose the right estimator/algorithm for our problems\",\n",
    "    \"3. Fit the model/algorithm and use it to make predictions on our data\",\n",
    "    \"4. Evaluating a model\",\n",
    "    \"5. Improve a model\",\n",
    "    \"6. Save and load a trained model\",\n",
    "    \"7. Putting it all together!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35b0ac9f-b39f-4871-830f-a73c2e9c6e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0. An end-to-end Scikit-Learn workflow',\n",
       " '1. Getting the data ready',\n",
       " '2. Choose the right estimator/algorithm for our problems',\n",
       " '3. Fit the model/algorithm and use it to make predictions on our data',\n",
       " '4. Evaluating a model',\n",
       " '5. Improve a model',\n",
       " '6. Save and load a trained model',\n",
       " '7. Putting it all together!']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "what_were_covering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53a50304-4b5e-4fbc-aa12-c7c45eb1fb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e8fdfa-f773-4928-a92a-4f71b23f60b4",
   "metadata": {},
   "source": [
    "\n",
    "## 0. An end-to-end Scikit-Learn workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7f85e21-b60f-42d3-95ba-cb3efe38dde8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "0        0   0     1       1  \n",
       "1        0   0     2       1  \n",
       "2        2   0     2       1  \n",
       "3        2   0     2       1  \n",
       "4        2   0     2       1  \n",
       "..     ...  ..   ...     ...  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "heart_disease = pd.read_csv(\"heart-disease.csv\")\n",
    "heart_disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45544f99-90b6-45c7-b756-05ead1ec177c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create X (features matrix)\n",
    "X = heart_disease.drop(\"target\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6456bc05-3d19-400a-891b-55af2429ec57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create y (labels)\n",
    "y = heart_disease[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "570fadde-d13f-4e98-9807-2ec67c592951",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestClassifier' object has no attribute 'get_parmas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m clf \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# We will keep the default hyperparameters\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m clf\u001b[38;5;241m.\u001b[39mget_parmas()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'get_parmas'"
     ]
    }
   ],
   "source": [
    "# 2. Choose the right model and hypermeters\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# We will keep the default hyperparameters\n",
    "\n",
    "clf.get_parmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95441778-f22d-44a4-915f-06a61cd3aaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Choose the right model and hyperparameters\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# We'll keep the default hyperparameters\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758601a6-3d99-4a34-a5d6-e81d5a1fbcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X (features matrix)\n",
    "X = heart_disease.drop(\"target\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0342284-bd5d-473e-9b21-8934201cfc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the  model to the data to the training data\n",
    "from sklearn.model_selection import train_test_split\\\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a03c793-a224-4132-bc40-578932a1405f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8409cbc0-c4a1-46b3-be5d-bd0944175cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming you have a dataset (for example, a pandas DataFrame)\n",
    "# x will be the feature columns, and y will be the target column\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Example: loading a dataset\n",
    "data = pd.read_csv(\"heart-disease.csv\")\n",
    "\n",
    "# Assuming 'target_column' is the column you're predicting\n",
    "x = data.drop('target', axis=1)  # Features\n",
    "y = data['target']               # Target variable\n",
    "\n",
    "# Now you can split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d060842-b99a-48f3-83c4-038eb39a8b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a841c2f-e269-4b71-9171-d16504d9007b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91ee465-97a1-4439-b7ea-5c0b97fce403",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4747cecf-4277-43bc-9019-e22a22dbdbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
    "\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3629419-f5dc-4f77-b2ee-2f41938c857f",
   "metadata": {},
   "source": [
    "### The given code snippet is used to evaluate the performance of a classification model. Here's an explanation of what each part does:\n",
    "\n",
    "### 1. **Classification Report**\n",
    "\n",
    "```python\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_preds))\n",
    "```\n",
    "\n",
    "- **Purpose**: Displays detailed metrics for each class in the classification problem.\n",
    "- **Metrics Included**:\n",
    "  - **Precision**: The proportion of true positive predictions out of all positive predictions. \\( \\text{Precision} = \\frac{\\text{TP}}{\\text{TP + FP}} \\)\n",
    "  - **Recall (Sensitivity)**: The proportion of actual positive cases correctly identified. \\( \\text{Recall} = \\frac{\\text{TP}}{\\text{TP + FN}} \\)\n",
    "  - **F1-Score**: The harmonic mean of precision and recall. \\( \\text{F1} = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision + Recall}} \\)\n",
    "  - **Support**: The number of occurrences of each class in the dataset.\n",
    "- **Output Example**:\n",
    "  ```\n",
    "               precision    recall  f1-score   support\n",
    "    Class 0       0.89      0.95      0.92        20\n",
    "    Class 1       0.85      0.80      0.82        15\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Confusion Matrix**\n",
    "\n",
    "```python\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_preds))\n",
    "```\n",
    "\n",
    "- **Purpose**: Displays a matrix summarizing the model's predictions.\n",
    "- **Structure**:\n",
    "  - Rows represent **actual classes** (true labels: `y_test`).\n",
    "  - Columns represent **predicted classes** (`y_preds`).\n",
    "- **Example**:\n",
    "  ```\n",
    "  [[50  2]\n",
    "   [ 5 43]]\n",
    "  ```\n",
    "  - `50`: True Positives for Class 0 (correctly predicted as Class 0).\n",
    "  - `2`: False Positives for Class 0 (incorrectly predicted as Class 1).\n",
    "  - `5`: False Negatives for Class 1 (incorrectly predicted as Class 0).\n",
    "  - `43`: True Positives for Class 1 (correctly predicted as Class 1).\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Accuracy Score**\n",
    "\n",
    "```python\n",
    "print(\"Accuracy Score:\")\n",
    "print(accuracy_score(y_test, y_preds))\n",
    "```\n",
    "\n",
    "- **Purpose**: Provides the overall accuracy of the model.\n",
    "- **Formula**:\n",
    "  \\[\n",
    "  \\text{Accuracy} = \\frac{\\text{Number of Correct Predictions}}{\\text{Total Number of Predictions}}\n",
    "  \\]\n",
    "- **Output Example**:\n",
    "  - If 93 out of 100 predictions are correct, accuracy will be `0.93`.\n",
    "\n",
    "---\n",
    "\n",
    "### Example Scenario\n",
    "\n",
    "- **`y_test`**: `[0, 1, 1, 0, 1, 0]` (true labels)\n",
    "- **`y_preds`**: `[0, 1, 0, 0, 1, 0]` (model predictions)\n",
    "\n",
    "**Output**:\n",
    "1. Classification Report:\n",
    "   ```\n",
    "               precision    recall  f1-score   support\n",
    "    0            0.75       1.00      0.86         3\n",
    "    1            1.00       0.67      0.80         3\n",
    "   ```\n",
    "2. Confusion Matrix:\n",
    "   ```\n",
    "   [[3 0]\n",
    "    [1 2]]\n",
    "   ```\n",
    "3. Accuracy Score:\n",
    "   ```\n",
    "   0.83\n",
    "   ```\n",
    "\n",
    "This means the model correctly predicted 5 out of 6 labels, achieving an accuracy of 83%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445c7780-cad4-420b-b3dc-115eae85dd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Assuming y_test (true labels) and y_preds (predicted labels) are already defined.\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_preds))\n",
    "\n",
    "print(\"Accuracy Score:\")\n",
    "print(accuracy_score(y_test, y_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff9afca-093f-4eda-b379-a4876f8fb14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load sample data\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_preds = model.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "# Optionally, print confusion matrix and accuracy score\n",
    "print(confusion_matrix(y_test, y_preds))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3d2eed-42c6-4080-b7ca-d70b95b726b6",
   "metadata": {},
   "source": [
    "### This code is testing the performance of a **Random Forest Classifier** with different numbers of trees (**estimators**) to see how it impacts the model's accuracy. Here's a simple explanation:\n",
    "\n",
    "### **Step-by-Step Explanation**:\n",
    "\n",
    "1. **Set Random Seed**:\n",
    "   ```python\n",
    "   np.random.seed(42)\n",
    "   ```\n",
    "   - Ensures that the results are reproducible. The same random numbers will be used every time the code runs.\n",
    "\n",
    "2. **Loop through different numbers of estimators**:\n",
    "   ```python\n",
    "   for i in range(10, 100, 10):\n",
    "   ```\n",
    "   - Creates a loop that starts at 10 and goes up to 90 (not including 100), increasing by 10 each time.\n",
    "   - The variable `i` will take values like 10, 20, 30, ..., 90.\n",
    "\n",
    "3. **Train a Random Forest Model**:\n",
    "   ```python\n",
    "   clf = RandomForestClassifier(n_estimators=i).fit(x_train, y_train)\n",
    "   ```\n",
    "   - For each value of `i`, it creates a Random Forest model with `i` trees (number of estimators).\n",
    "   - Fits (trains) the model on the training data (`x_train` and `y_train`).\n",
    "\n",
    "4. **Evaluate the Model**:\n",
    "   ```python\n",
    "   print(f\"Model Accuracy On Test set: {clf.score(x_test, y_test) * 100:.2f}%\")\n",
    "   ```\n",
    "   - Calculates the accuracy of the model on the test data (`x_test` and `y_test`).\n",
    "   - `clf.score()` gives the accuracy as a decimal (e.g., `0.85` for 85%).\n",
    "   - This value is multiplied by 100 and formatted to two decimal places (e.g., `85.00%`).\n",
    "\n",
    "5. **Print Results**:\n",
    "   ```python\n",
    "   print(f\"Trying model with {i} estimators....\")\n",
    "   print(\"\")\n",
    "   ```\n",
    "   - Displays how many estimators are being used (`i`) and the resulting test accuracy.\n",
    "\n",
    "### **What the Code is Doing Overall**:\n",
    "- Trains **multiple Random Forest models** with different numbers of trees (`10, 20, 30, ..., 90`).\n",
    "- Measures the accuracy of each model on the test dataset.\n",
    "- Prints the accuracy for each configuration to compare which number of trees gives the best results.\n",
    "\n",
    "### Example Output:\n",
    "If the accuracy improves as the number of estimators increases:\n",
    "```\n",
    "Trying model with 10 estimators....\n",
    "Model Accuracy On Test set: 78.50%\n",
    "\n",
    "Trying model with 20 estimators....\n",
    "Model Accuracy On Test set: 82.30%\n",
    "\n",
    "Trying model with 30 estimators....\n",
    "Model Accuracy On Test set: 85.00%\n",
    "\n",
    "...\n",
    "```\n",
    "\n",
    "By observing the output, you can decide which number of trees (n_estimators) gives the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4d185a-d41c-49a4-8f86-81c0c2700da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improve a model \n",
    "# Try different amount of n_estimators\n",
    "\n",
    "np.random.seed(42)\n",
    "for i in range(10, 100, 10):\n",
    "    print(f\"Trying moderl with {i} estimators....\")\n",
    "    clf = RandomForestClassifier(n_estimators=i).fit(x_train, y_train)\n",
    "    print(f\"Model Accuracy On Test set: {clf.score(x_test, y_test) * 100:.2f}%\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32c7965-ab66-4ac7-ba80-70deeb691bdc",
   "metadata": {},
   "source": [
    "### This code is testing the performance of a **Random Forest Classifier** with different numbers of trees (**estimators**) to see how it impacts the model's accuracy. Here's a simple explanation:\n",
    "\n",
    "### **Step-by-Step Explanation**:\n",
    "\n",
    "1. **Set Random Seed**:\n",
    "   ```python\n",
    "   np.random.seed(42)\n",
    "   ```\n",
    "   - Ensures that the results are reproducible. The same random numbers will be used every time the code runs.\n",
    "\n",
    "2. **Loop through different numbers of estimators**:\n",
    "   ```python\n",
    "   for i in range(10, 100, 10):\n",
    "   ```\n",
    "   - Creates a loop that starts at 10 and goes up to 90 (not including 100), increasing by 10 each time.\n",
    "   - The variable `i` will take values like 10, 20, 30, ..., 90.\n",
    "\n",
    "3. **Train a Random Forest Model**:\n",
    "   ```python\n",
    "   clf = RandomForestClassifier(n_estimators=i).fit(x_train, y_train)\n",
    "   ```\n",
    "   - For each value of `i`, it creates a Random Forest model with `i` trees (number of estimators).\n",
    "   - Fits (trains) the model on the training data (`x_train` and `y_train`).\n",
    "\n",
    "4. **Evaluate the Model**:\n",
    "   ```python\n",
    "   print(f\"Model Accuracy On Test set: {clf.score(x_test, y_test) * 100:.2f}%\")\n",
    "   ```\n",
    "   - Calculates the accuracy of the model on the test data (`x_test` and `y_test`).\n",
    "   - `clf.score()` gives the accuracy as a decimal (e.g., `0.85` for 85%).\n",
    "   - This value is multiplied by 100 and formatted to two decimal places (e.g., `85.00%`).\n",
    "\n",
    "5. **Print Results**:\n",
    "   ```python\n",
    "   print(f\"Trying model with {i} estimators....\")\n",
    "   print(\"\")\n",
    "   ```\n",
    "   - Displays how many estimators are being used (`i`) and the resulting test accuracy.\n",
    "\n",
    "### **What the Code is Doing Overall**:\n",
    "- Trains **multiple Random Forest models** with different numbers of trees (`10, 20, 30, ..., 90`).\n",
    "- Measures the accuracy of each model on the test dataset.\n",
    "- Prints the accuracy for each configuration to compare which number of trees gives the best results.\n",
    "\n",
    "### Example Output:\n",
    "If the accuracy improves as the number of estimators increases:\n",
    "```\n",
    "Trying model with 10 estimators....\n",
    "Model Accuracy On Test set: 78.50%\n",
    "\n",
    "Trying model with 20 estimators....\n",
    "Model Accuracy On Test set: 82.30%\n",
    "\n",
    "Trying model with 30 estimators....\n",
    "Model Accuracy On Test set: 85.00%\n",
    "\n",
    "...\n",
    "```\n",
    "\n",
    "By observing the output, you can decide which number of trees (n_estimators) gives the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa2f382-ea53-406c-8abf-363a3e5296f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd75e1aa-dc82-475a-94e4-8132871ba1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380afc0d-1dcb-426e-ae6c-4be2ec627b4e",
   "metadata": {},
   "source": [
    "## Save a model and Load It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44116d0-0e0d-4aab-9f1c-49a120e75890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(clf, open(\"random_forest_model_1.pk1\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b312754c-387c-4484-868f-7c96b3d7cfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(\"random_forest_model_1.pk1\", \"rb\"))\n",
    "loaded_model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e31d6b-e55d-4eb3-a9d1-d81b128f5a68",
   "metadata": {},
   "source": [
    "### This code is used to **load a saved machine learning model** and evaluate its performance on a test dataset. Here's a simple explanation:\n",
    "\n",
    "---\n",
    "\n",
    "### **What Each Part Does:**\n",
    "\n",
    "1. **`pickle.load(open(\"random_forest_model_1.pk1\", \"rb\"))`:**\n",
    "   - **`pickle`**: A Python library used for saving (serializing) and loading (deserializing) Python objects, such as a trained machine learning model.\n",
    "   - **`open(\"random_forest_model_1.pk1\", \"rb\")`**:\n",
    "     - Opens the file `\"random_forest_model_1.pk1\"` in **read-binary mode** (`\"rb\"`).\n",
    "     - This file contains the saved Random Forest model.\n",
    "   - **`pickle.load(...)`**: Reads the saved model from the file and loads it back into Python as an object.\n",
    "   - **Result**: The loaded model is assigned to the variable `loaded_model`.\n",
    "\n",
    "2. **`loaded_model.score(x_test, y_test)`:**\n",
    "   - **`score()`**: A method of the Random Forest model that calculates its **accuracy**.\n",
    "   - **`x_test`**: The test dataset features (input values).\n",
    "   - **`y_test`**: The actual labels for the test dataset (true values).\n",
    "   - The method compares the model's predictions on `x_test` with `y_test` to compute the **accuracy score** (the percentage of correct predictions).\n",
    "\n",
    "---\n",
    "\n",
    "### **What the Code Does Overall:**\n",
    "1. Loads a pre-trained **Random Forest model** saved in the file `\"random_forest_model_1.pk1\"`.\n",
    "2. Tests the loaded model's accuracy using the test data (`x_test` and `y_test`).\n",
    "3. Outputs the accuracy score.\n",
    "\n",
    "---\n",
    "\n",
    "### **Why Use This Code?**\n",
    "- If you previously trained a model and saved it to a file, this code allows you to:\n",
    "  - Load it without re-training.\n",
    "  - Evaluate or use the model for predictions.\n",
    "\n",
    "---\n",
    "\n",
    "### Example:\n",
    "If `random_forest_model_1.pk1` was trained earlier and the accuracy on `x_test` and `y_test` is 85%, running the code would output something like:\n",
    "```python\n",
    "0.85\n",
    "```\n",
    "\n",
    "This means the model correctly predicted 85% of the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49afac5-07e3-489d-9e3a-fada38264d35",
   "metadata": {},
   "source": [
    "## Debugging Warning In Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8a12f4-fe40-459f-8457-8686e7b4b1d4",
   "metadata": {},
   "source": [
    "### In Jupyter notebooks, warnings often appear when your code might not be ideal or could potentially cause issues in the future, but it still runs. Debugging warnings are meant to inform you about potential problems without stopping the execution of your code.\n",
    "\n",
    "### Example of a Debugging Warning in Jupyter\n",
    "\n",
    "Let’s consider the following scenario, where we’re using **`pandas`** to manipulate data:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creating a DataFrame with duplicate column names\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6],\n",
    "    'B': [7, 8, 9],  # Duplicate column name 'B'\n",
    "    'C': [10, 11, 12]\n",
    "})\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "In this code, we have a **duplicate column name** (`'B'`), which may lead to some unexpected behavior. When running the code in Jupyter, you'll likely see the following warning:\n",
    "\n",
    "```\n",
    "/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py:1630: UserWarning: DataFrame columns are not unique, some columns will be omitted\n",
    "  warnings.warn(\"DataFrame columns are not unique, some columns will be omitted\")\n",
    "```\n",
    "\n",
    "### Explanation of the Warning:\n",
    "- **Warning Message**: `UserWarning: DataFrame columns are not unique, some columns will be omitted`.\n",
    "- **Cause**: The code has duplicate column names, which can lead to ambiguity when accessing or manipulating the DataFrame.\n",
    "- **Impact**: Pandas may automatically ignore the second occurrence of the column (in this case, the second `'B'`), leading to potential data loss or errors in your analysis.\n",
    "\n",
    "### Debugging and Fixing the Warning:\n",
    "\n",
    "To fix this issue, you can ensure that column names are unique, like this:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creating a DataFrame with unique column names\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6],\n",
    "    'B_2': [7, 8, 9],  # Renaming duplicate column 'B'\n",
    "    'C': [10, 11, 12]\n",
    "})\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "Now the warning will no longer appear because the column names are unique.\n",
    "\n",
    "### Common Debugging Warnings in Jupyter:\n",
    "\n",
    "1. **Deprecation Warnings**: These occur when a feature or function you’re using is outdated and will be removed in future versions of the library.\n",
    "   - Example:\n",
    "     ```python\n",
    "     import pandas as pd\n",
    "     \n",
    "     # Using a deprecated method\n",
    "     df = pd.DataFrame({'A': [1, 2, 3]})\n",
    "     df.set_index('A', inplace=True)  # Deprecated method\n",
    "     ```\n",
    "\n",
    "     You may see a warning like:\n",
    "     ```\n",
    "     FutureWarning: 'inplace' is deprecated. Use 'drop' instead.\n",
    "     ```\n",
    "\n",
    "2. **Performance Warnings**: These warn you if your code might not perform well, for example, when handling large datasets.\n",
    "   - Example:\n",
    "     ```python\n",
    "     import numpy as np\n",
    "     import pandas as pd\n",
    "\n",
    "     # Creating a large DataFrame\n",
    "     df = pd.DataFrame(np.random.randn(1000000, 2), columns=['A', 'B'])\n",
    "     df['C'] = df['A'] + df['B']  # May trigger a warning if operation is inefficient\n",
    "     ```\n",
    "\n",
    "3. **Convergence Warnings**: These occur in machine learning when a model doesn't converge during training (i.e., it doesn’t reach optimal performance).\n",
    "   - Example:\n",
    "     ```python\n",
    "     from sklearn.linear_model import LogisticRegression\n",
    "     \n",
    "     # Trying to fit a model with insufficient data\n",
    "     model = LogisticRegression(max_iter=10)  # Low iteration limit\n",
    "     model.fit(X_train, y_train)\n",
    "     ```\n",
    "\n",
    "     You might see:\n",
    "     ```\n",
    "     ConvergenceWarning: lbfgs failed to converge (max_iter=10). Increase the number of iterations.\n",
    "     ```\n",
    "\n",
    "### How to Suppress Warnings:\n",
    "\n",
    "If you're aware of the warning and want to suppress it, you can use Python's **`warnings` module**:\n",
    "\n",
    "```python\n",
    "import warnings\n",
    "\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "```\n",
    "\n",
    "This will stop the `UserWarning` from appearing.\n",
    "\n",
    "### Conclusion:\n",
    "Warnings in Jupyter help you debug potential issues or inefficient practices in your code. It's important to understand and fix these warnings, as they can indicate problems that might affect the performance or correctness of your program."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad21681b-4bb3-4faa-87ac-a138209993fe",
   "metadata": {},
   "source": [
    "## Gaining Our Data Ready To Be Used With  Machine Learning\n",
    "\n",
    "Three main things we have to do:\n",
    "\n",
    "  1: Split the data into features and labels (usually 'x' & 'y')\n",
    "  \n",
    "  2: Filling (also called imputing) or disregarding missinfg values\n",
    "  \n",
    "  3: Converting non-numerical values to numerical values (also called features encoding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ff2cb7-7301-4a9b-b08c-9958e11dad5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d17d27e-702a-4669-98ee-82339cfc17bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = heart_disease.drop(\"target\", axis=1)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93a0729-da70-4f82-8212-8eb6328f5a9a",
   "metadata": {},
   "source": [
    "### This code is performing some basic operations on a dataset, specifically focusing on a **DataFrame** (a table-like structure in **pandas**). Here's what each part does:\n",
    "\n",
    "### **Code Explanation**:\n",
    "\n",
    "1. **`heart_disease.drop(\"target\", axis=1)`**:\n",
    "   - **`heart_disease`**: This is the name of the dataset (a pandas DataFrame) that likely contains information about various heart disease factors.\n",
    "   - **`drop(\"target\", axis=1)`**: \n",
    "     - **`\"target\"`**: This refers to a column in the DataFrame named `\"target\"`. The `\"target\"` column typically contains the label or outcome you're trying to predict (for example, whether someone has heart disease or not).\n",
    "     - **`axis=1`**: This tells pandas to drop a **column** (not a row). If you used `axis=0`, it would drop rows instead of columns.\n",
    "     - So, this operation removes the `\"target\"` column from the `heart_disease` DataFrame.\n",
    "\n",
    "2. **`x = ...`**:\n",
    "   - The result of the `drop` operation (the DataFrame without the `\"target\"` column) is assigned to the variable `x`. This means `x` will contain all the features (input data) except the target variable.\n",
    "\n",
    "3. **`x.head()`**:\n",
    "   - **`head()`**: This is a pandas function that shows the first 5 rows of the DataFrame by default.\n",
    "   - In this case, `x.head()` will display the first 5 rows of the `x` DataFrame, which contains the features (input data) for predicting heart disease, excluding the `\"target\"` column.\n",
    "\n",
    "### **Summary**:\n",
    "\n",
    "- **Purpose**: This code removes the `\"target\"` column from the `heart_disease` DataFrame (which is likely the label you want to predict) and stores the remaining data (the features) in `x`. Then it displays the first 5 rows of `x`.\n",
    "\n",
    "### **Example**:\n",
    "\n",
    "If `heart_disease` looks like this:\n",
    "\n",
    "| age | cholesterol | target |\n",
    "| --- | ----------- | ------ |\n",
    "| 45  | 200         | 1      |\n",
    "| 60  | 180         | 0      |\n",
    "| 50  | 220         | 1      |\n",
    "| 55  | 240         | 0      |\n",
    "\n",
    "After running the code, `x` will look like this:\n",
    "\n",
    "| age | cholesterol |\n",
    "| --- | ----------- |\n",
    "| 45  | 200         |\n",
    "| 60  | 180         |\n",
    "| 50  | 220         |\n",
    "| 55  | 240         |\n",
    "\n",
    "And `x.head()` will show the first 5 rows of this modified DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79781618-bbf0-4a85-8991-f7d835830abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = heart_disease[\"target\"]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4209f2-b385-4312-9ae4-a2049bc02677",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = heart_disease[\"cp\"]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c701a9e-e9fc-49c0-a9d6-2daf34e55896",
   "metadata": {},
   "source": [
    "### This code is extracting the **target column** (which typically contains the labels or outcomes you want to predict) from the `heart_disease` DataFrame and storing it in the variable `y`. Here's a breakdown of each part:\n",
    "\n",
    "### **Code Explanation**:\n",
    "\n",
    "1. **`heart_disease[\"target\"]`**:\n",
    "   - **`heart_disease`**: This is the original DataFrame that contains all the data about heart disease.\n",
    "   - **`[\"target\"]`**: This is selecting the column named `\"target\"` from the `heart_disease` DataFrame. The `\"target\"` column typically holds the labels or outcomes you are trying to predict (for example, `1` might mean \"has heart disease,\" and `0` means \"no heart disease\").\n",
    "\n",
    "2. **`y = ...`**:\n",
    "   - The result of selecting the `\"target\"` column is assigned to the variable `y`. So, `y` will now contain the labels (target values) of the dataset.\n",
    "\n",
    "3. **`y.head()`**:\n",
    "   - **`head()`**: This is a pandas function that displays the first 5 rows of the DataFrame or Series.\n",
    "   - In this case, since `y` is a pandas **Series** (a single column), `y.head()` will display the first 5 values in the `y` series.\n",
    "\n",
    "### **Summary**:\n",
    "- **Purpose**: This code extracts the `\"target\"` column from the `heart_disease` DataFrame and stores it in `y`. Then, it displays the first 5 values of `y`, which are the labels (outcomes) for heart disease prediction.\n",
    "\n",
    "### **Example**:\n",
    "\n",
    "If the `heart_disease` DataFrame looks like this:\n",
    "\n",
    "| age | cholesterol | target |\n",
    "| --- | ----------- | ------ |\n",
    "| 45  | 200         | 1      |\n",
    "| 60  | 180         | 0      |\n",
    "| 50  | 220         | 1      |\n",
    "| 55  | 240         | 0      |\n",
    "\n",
    "After running the code, `y` will look like this:\n",
    "\n",
    "| target |\n",
    "| ------ |\n",
    "| 1      |\n",
    "| 0      |\n",
    "| 1      |\n",
    "| 0      |\n",
    "\n",
    "And `y.head()` will display:\n",
    "\n",
    "```\n",
    "0    1\n",
    "1    0\n",
    "2    1\n",
    "3    0\n",
    "Name: target, dtype: int64\n",
    "```\n",
    "\n",
    "This means `y` holds the target labels, and `y.head()` shows the first few target labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561a1533-a322-419d-afdf-d3a4691f8534",
   "metadata": {},
   "source": [
    "## Split The Data Into Training And Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde43de8-d7d4-404c-8e42-a20249477e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6704d0c7-b5ac-43c8-864f-c2c1ee339b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb09d05-0950-49ea-be5d-6eb59a5d7bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e134d991-a85a-4120-8933-714a28b662a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(heart_disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4723b5cf-a2fd-446f-841f-c9da66a4e269",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape[0] * 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8deb227-aae0-41eb-b68a-52690611a5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "242 + 61"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e203df-b903-4c9d-9a2b-aefef3f94694",
   "metadata": {},
   "source": [
    "## Make sure it's all numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da85cb54-0565-4592-a40b-b2d7aece7800",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales = pd.read_csv(\"car-sales-extended.csv\")\n",
    "car_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a463bb-7f68-47f3-a408-189e5acb3b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(car_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debef1dd-0022-4e98-8d01-8c8b1454dfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Into x/y\n",
    "\n",
    "x = car_sales.drop(\"Price\", axis=1)\n",
    "y = car_sales[\"Price\"]\n",
    "\n",
    "# Split into training and test\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e47835-2b62-49c3-9fe5-83b753db839e",
   "metadata": {},
   "source": [
    "## Covert Data Into Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e00fe4-841d-42ba-80d9-ae93f1692a0c",
   "metadata": {},
   "source": [
    "## Categories Into Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350c103c-9539-485c-b880-68c4f7baf0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import oneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = oneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                 one_hot,\n",
    "                                 categorical_features)]\n",
    "                                 remainder=\"passthrough\")\n",
    "transformed_x = transformer.fit_transform(x)\n",
    "transformed_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f923dd50-b0e6-4cb7-9328-021c6bb2a4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Define the categorical features you want to one-hot encode\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "# Define the ColumnTransformer\n",
    "transformer = ColumnTransformer(\n",
    "    [(\"one_hot\", one_hot, categorical_features)],\n",
    "    remainder=\"passthrough\"  # Keep other columns as they are\n",
    ")\n",
    "\n",
    "# Apply the transformation to the input data x\n",
    "transformed_x = transformer.fit_transform(x)\n",
    "\n",
    "# Display the transformed data\n",
    "transformed_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97daba86-ef2b-47b0-ad67-6706f241f274",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28ba327-5d21-4908-a35d-43edc05d5655",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(transformed_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4b51a8-6e6f-44d6-9bc5-ef110e78d7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dumies = pd.get_dummies(car_sales[[\"Make\", \"Colour\", \"Doors\"]])\n",
    "dumies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40da979b-82a9-41a0-8c8f-209391d7d579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build machine learning model\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegresor\n",
    "model = RandomForestRegressor()\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f80491-436e-4620-b439-13fd97188166",
   "metadata": {},
   "outputs": [],
   "source": [
    "dumies = pd.get_dummies(car_sales[[\"Make\", \"Colour\", \"Doors\"]])\n",
    "dumies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44c2b1e-371b-49d8-b14b-a86bbd928209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's refit the model\n",
    "\n",
    "np.random.seed(42)\n",
    "x_train, x_test, y_train, y_test = train_test_split(transformed_x,\n",
    "                                                   y,\n",
    "                                                  test_size=0.2)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4306e251-260d-4a66-82c8-c5cfc5278e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split if not already imported\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split the transformed features and labels into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    transformed_x,  # Transformed features\n",
    "    y,              # Labels\n",
    "    test_size=0.2   # 20% of the data will be used for testing\n",
    ")\n",
    "\n",
    "# Make sure the model is defined and initialized\n",
    "# Example: Initialize a Random Forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# The model is now trained\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5a8a6a-dc62-45d0-832c-6697a2313244",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c9d2fc-cef3-4ca0-97e0-6e1661830e55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c01a9e7-f5b7-425f-acfa-cc5329f3e9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Example dataset with string data\n",
    "data = {\n",
    "    'Color': ['Red', 'Blue', 'Green', 'Blue', 'Green'],\n",
    "    'Size': ['M', 'L', 'S', 'S', 'M'],\n",
    "    'Price': ['High', 'Low', 'Medium', 'Medium', 'High'],\n",
    "    'Target': ['Yes', 'No', 'Yes', 'No', 'Yes']\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display original data\n",
    "df\n",
    "\n",
    "# Step 1: Convert string columns to numbers using Label Encoding or One-Hot Encoding\n",
    "\n",
    "# Label Encoding for the 'Target' column (binary outcome)\n",
    "label_encoder = LabelEncoder()\n",
    "df['Target'] = label_encoder.fit_transform(df['Target'])\n",
    "\n",
    "# One-Hot Encoding for other categorical columns (e.g., 'Color', 'Size', 'Price')\n",
    "# Create the ColumnTransformer\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot', OneHotEncoder(), ['Color', 'Size', 'Price'])\n",
    "    ], \n",
    "    remainder='passthrough'  # Leave 'Target' column as it is\n",
    ")\n",
    "\n",
    "# Apply the transformation to the DataFrame\n",
    "df_transformed = column_transformer.fit_transform(df)\n",
    "\n",
    "# Convert the transformed DataFrame back to a DataFrame for easier viewing\n",
    "df_transformed = pd.DataFrame(df_transformed, columns=['Red', 'Blue', 'Green', 'L', 'M', 'S', 'High', 'Low', 'Medium', 'Target'])\n",
    "\n",
    "# Display the transformed DataFrame\n",
    "df_transformed\n",
    "\n",
    "# Step 2: Split data into features (X) and target (y)\n",
    "X = df_transformed.drop('Target', axis=1)\n",
    "y = df_transformed['Target']\n",
    "\n",
    "# Step 3: Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Initialize and train the model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Make predictions and evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Step 6: Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef881931-51f3-4506-ae9c-80e300ae5256",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bf9737-ec52-482f-b959-e5284d76ec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbce5bc-3d03-45c2-a074-54d8e239bb54",
   "metadata": {},
   "source": [
    "## What if there were missing values ?\n",
    "1. Fill them with some value (also known as immputation).\n",
    "2. Remove the samples with missing data altogether.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845cca71-4003-40cb-b5de-3971c5fe4513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import car sales missing data\n",
    "import pandas as pd\n",
    "car_sales_missing = pd.read_csv(\"car-sales-missing-data.csv\")\n",
    "car_sales_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255647b2-8aa2-46ab-b40e-be8826e832af",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.isna().sum()#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b625b69-d5da-4144-81e8-bd65406a7ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create x and y\n",
    "\n",
    "x = car_sales_missing.drop(\"Price\", axis=1)\n",
    "y = car_sales_missing(\"Price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509afee3-cd13-413d-9167-6f2d918f4d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try and convert or data to numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Define the categorical features you want to one-hot encode\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "# Define the ColumnTransformer\n",
    "transformer = ColumnTransformer(\n",
    "    [(\"one_hot\", one_hot, categorical_features)],\n",
    "    remainder=\"passthrough\"  # Keep other columns as they are\n",
    ")\n",
    "\n",
    "# Apply the transformation to the input data x\n",
    "transformed_x = transformer.fit_transform(x)\n",
    "\n",
    "# Display the transformed data\n",
    "transformed_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7baf46-8f0c-404f-a51b-d3928cfe853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc140ee-a9b1-4e43-bed1-3badf73e1959",
   "metadata": {},
   "source": [
    "### Fill missing data with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180c325a-7408-430d-b9e6-0c581f487bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the \"Make\" column\n",
    "car_sales_missing[\"Make\"].fillna(\"missing\", inplace=True)\n",
    "\n",
    "# Fill the \"Colour\" column\n",
    "car_sales_missing[\"Colour\"].fillna(\"missing\", inplace=True)\n",
    "\n",
    "# Fill the \"Odometer (KM)\" column with the mean value\n",
    "car_sales_missing[\"Odometer\"].fillna(car_sales_missing[\"Odometer\"].mean(), inplace=True)\n",
    "\n",
    "# Fill the \"Doors\" column with a default value of 4\n",
    "car_sales_missing[\"Doors\"].fillna(4, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53911be0-3841-4038-b60d-d0960e4953ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check our dataframe again\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6072b1dd-4288-4459-a9ba-b87a29046567",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39a285e-50d6-4036-acf7-bd6c1636c731",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb2fabf-ee5f-41fb-94d9-5324d29ee3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows withb missing Price value\n",
    "car_sales_missing.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbccb1f-75f6-4dd6-b1e1-95ffbeac341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4945285-ba70-4bc6-9a14-529e9e5ea47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7378af4c-ec9d-4667-bd08-920c56003a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(car_sales_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8987e39e-8811-45d9-82ce-cb40bd0e2cdf",
   "metadata": {},
   "source": [
    "### ### **Handling Missing Values with Pandas**\n",
    "\n",
    "Missing values in a dataset can cause issues in analysis and machine learning models. Pandas provides several methods to detect, remove, and handle missing values effectively.\n",
    "\n",
    "---\n",
    "\n",
    "#### **1. Detecting Missing Values**\n",
    "\n",
    "Pandas uses `NaN` (Not a Number) to represent missing values. You can detect them using the following methods:\n",
    "\n",
    "- `isna()` or `isnull()`: Returns `True` for missing values.\n",
    "- `notna()` or `notnull()`: Returns `True` for non-missing values.\n",
    "\n",
    "##### **Code Example:**\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creating a DataFrame with missing values\n",
    "data = {\n",
    "    \"Name\": [\"Akhilesh\", \"Chetna\", None, \"Rahul\"],\n",
    "    \"Age\": [25, None, 23, 22],\n",
    "    \"Score\": [90, 85, None, 88]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Detecting missing values\n",
    "print(df.isna())  # Shows True where values are missing\n",
    "print(df.isnull())  # Same as isna()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Dropping Missing Values**\n",
    "\n",
    "- `dropna()`: Removes rows or columns with missing values.\n",
    "\n",
    "##### **Parameters:**\n",
    "- `axis=0`: Drops rows (default).\n",
    "- `axis=1`: Drops columns.\n",
    "- `how='any'`: Drops rows/columns with any missing values (default).\n",
    "- `how='all'`: Drops rows/columns only if all values are missing.\n",
    "- `thresh`: Retains rows/columns with at least a specified number of non-missing values.\n",
    "\n",
    "##### **Code Example:**\n",
    "```python\n",
    "# Dropping rows with any missing values\n",
    "df_dropped_rows = df.dropna()\n",
    "\n",
    "# Dropping columns with any missing values\n",
    "df_dropped_columns = df.dropna(axis=1)\n",
    "\n",
    "# Dropping rows where all values are missing\n",
    "df_drop_all = df.dropna(how='all')\n",
    "\n",
    "# Dropping rows with fewer than 2 non-missing values\n",
    "df_thresh = df.dropna(thresh=2)\n",
    "\n",
    "print(df_dropped_rows)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Filling Missing Values**\n",
    "\n",
    "- `fillna()`: Fills missing values with a specified value or method.\n",
    "\n",
    "##### **Options:**\n",
    "- Replace with a scalar value (e.g., 0, mean, or median).\n",
    "- `method='ffill'`: Forward fill (propagates the last valid value forward).\n",
    "- `method='bfill'`: Backward fill (propagates the next valid value backward).\n",
    "\n",
    "##### **Code Example:**\n",
    "```python\n",
    "# Filling missing values with a constant\n",
    "df_filled_constant = df.fillna(0)\n",
    "\n",
    "# Filling missing values with the mean of the column\n",
    "df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "\n",
    "# Forward fill\n",
    "df_ffill = df.fillna(method='ffill')\n",
    "\n",
    "# Backward fill\n",
    "df_bfill = df.fillna(method='bfill')\n",
    "\n",
    "print(df_filled_constant)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Interpolating Missing Values**\n",
    "\n",
    "- `interpolate()`: Fills missing values using interpolation techniques.\n",
    "\n",
    "##### **Code Example:**\n",
    "```python\n",
    "# Interpolating missing values linearly\n",
    "df_interpolated = df.interpolate(method='linear')\n",
    "\n",
    "print(df_interpolated)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **5. Replacing Missing Values**\n",
    "\n",
    "- `replace()`: Replaces specific missing values.\n",
    "\n",
    "##### **Code Example:**\n",
    "```python\n",
    "# Replacing NaN with a specific value\n",
    "df_replaced = df.replace(to_replace=None, value=\"Unknown\")\n",
    "\n",
    "print(df_replaced)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **6. Checking for Missing Values Summary**\n",
    "\n",
    "- `isna().sum()`: Provides a count of missing values in each column.\n",
    "\n",
    "##### **Code Example:**\n",
    "```python\n",
    "# Checking the count of missing values\n",
    "missing_summary = df.isna().sum()\n",
    "\n",
    "print(missing_summary)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Considerations**\n",
    "- **When to Drop?** If the amount of missing data is significant and cannot be reasonably filled.\n",
    "- **When to Fill?** If the missing data is small and filling it won't distort the dataset.\n",
    "- **Interpolation?** Useful for time-series data or datasets with a logical numerical sequence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8ae903-ab3e-4eec-a1a2-ab7b5d34f719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating a DataFrame with missing values\n",
    "data = {\n",
    "    \"Name\": [\"Akhilesh\", \"Chetna\", None, \"Rahul\"],\n",
    "    \"Age\": [25, None, 23, 22],\n",
    "    \"Score\": [90, 85, None, 88]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Detecting missing values\n",
    "print(df.isna())  # Shows True where values are missing\n",
    "print(df.isnull())  # Same as isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6ce22a-73f2-4fd4-8bb8-bd01fad79e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows with any missing values\n",
    "df_dropped_rows = df.dropna()\n",
    "\n",
    "# Dropping columns with any missing values\n",
    "df_dropped_columns = df.dropna(axis=1)\n",
    "\n",
    "# Dropping rows where all values are missing\n",
    "df_drop_all = df.dropna(how='all')\n",
    "\n",
    "# Dropping rows with fewer than 2 non-missing values\n",
    "df_thresh = df.dropna(thresh=2)\n",
    "\n",
    "print(df_dropped_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2d61b2-1193-4eae-afff-5d0412eb0993",
   "metadata": {},
   "source": [
    "### Fill missing values with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50967415-d828-4a23-a980-b709703cfd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing = pd.read_csv(\"car-sales-extended-missing-data.csv\")\n",
    "car_sales_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bae9749-7fb9-482e-a67d-9f90e58c8158",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d83513-a52c-4890-81dc-1a229f71438b",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.dropna(subset=[\"Price\"], inplace = True)\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1138392e-01fc-4131-88de-42fb39ad4805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SDplit into x and y\n",
    "x = car_sales_missing.drop(\"Price\", axis=1)\n",
    "y = car_sales_missing[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c10c614-e928-4555-84bf-c181c3366bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Fill categorical values with \"missing\" and numerical values with mean\n",
    "cat_imputer = SimpleImputer(strategy=\"constant\", fill_value=\"missing\")\n",
    "door_imputer = SimpleImputer(strategy=\"constant\", fill_value=4)\n",
    "num_imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "# Define columns\n",
    "cat_features = [\"Make\", \"Colour\"]\n",
    "door_feature = [\"Doors\"]\n",
    "num_feature = [\"Odometer\"]\n",
    "\n",
    "# Create an imputer (something that fills missing data)\n",
    "imputer = ColumnTransformer([\n",
    "    (\"cat_imputer\", cat_imputer, cat_features),\n",
    "    (\"door_imputer\", door_imputer, door_feature),\n",
    "    (\"num_imputer\", num_imputer, num_feature)\n",
    "])\n",
    "\n",
    "# Transform the data\n",
    "\n",
    "filled_x =- imputer.fit_transform(x)\n",
    "filled_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecded8cf-18db-474d-b485-3e769a7350fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame (replace this with your actual data)\n",
    "x = pd.DataFrame({\n",
    "    \"Make\": [\"Toyota\", \"Ford\", None, \"BMW\"],\n",
    "    \"Colour\": [None, \"Blue\", \"Red\", None],\n",
    "    \"Doors\": [4, None, None, 4],\n",
    "    \"Odometer\": [12345, None, 67890, None]\n",
    "})\n",
    "\n",
    "# Fill categorical values with \"missing\" and numerical values with mean\n",
    "cat_imputer = SimpleImputer(strategy=\"constant\", fill_value=\"missing\")\n",
    "door_imputer = SimpleImputer(strategy=\"constant\", fill_value=4)\n",
    "num_imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "# Define columns\n",
    "cat_features = [\"Make\", \"Colour\"]\n",
    "door_feature = [\"Doors\"]\n",
    "num_feature = [\"Odometer\"]\n",
    "\n",
    "# Create an imputer (something that fills missing data)\n",
    "imputer = ColumnTransformer([\n",
    "    (\"cat_imputer\", cat_imputer, cat_features),\n",
    "    (\"door_imputer\", door_imputer, door_feature),\n",
    "    (\"num_imputer\", num_imputer, num_feature)\n",
    "])\n",
    "\n",
    "# Transform the data\n",
    "filled_x = imputer.fit_transform(x)\n",
    "\n",
    "# Convert the transformed data back to a DataFrame\n",
    "filled_x_df = pd.DataFrame(\n",
    "    filled_x, \n",
    "    columns=cat_features + door_feature + num_feature\n",
    ")\n",
    "\n",
    "print(filled_x_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa749067-7f79-49e9-82df-969763f57075",
   "metadata": {},
   "source": [
    "## Choosing the right algorithum for your problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad29499-a982-48b1-9b91-13036cbe7cf5",
   "metadata": {},
   "source": [
    "## Picking a ML  model for a regression problem\n",
    "\n",
    "Let's use the California Housingh dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0be8957-6597-495f-9d43-6c77e5ce4815",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "housing;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2807782b-856f-4a7d-99d9-d693466983cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Load the California Housing dataset\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# Check the structure of the dataset\n",
    "print(housing.keys())  # Outputs the dictionary keys\n",
    "\n",
    "# View the description of the dataset\n",
    "print(housing['DESCR'])\n",
    "\n",
    "# View the feature names\n",
    "print(\"Feature names:\", housing['feature_names'])\n",
    "\n",
    "# Convert the dataset to a DataFrame for better visualization (optional)\n",
    "import pandas as pd\n",
    "housing_df = pd.DataFrame(housing['data'], columns=housing['feature_names'])\n",
    "\n",
    "# Add the target column to the DataFrame\n",
    "housing_df['Target'] = housing['target']\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(housing_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d5fca2-bbb6-47fa-8089-6a0f37da8396",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = pd.DataFrame(housing[\"data\"], columns=housing[\"feature_names\"])\n",
    "housing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a16230-a727-4651-93c2-24d360028527",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = pd.DataFrame(housing[\"data\"], columns=housing[\"feature_names\"])\n",
    "\n",
    "# Add the target (housing prices) to a new column\n",
    "housing_df[\"Target\"] = housing[\"target\"]\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(housing_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4df27c-47a1-4c13-ae43-582423e5ccd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the \"MedInc\" column from the DataFrame\n",
    "housing_df.drop(\"MedInc\", axis=1, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(housing_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b5b4bf-8ded-41fa-9d15-feaf968a62d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries and estimators\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "x = housing_df.drop(\"Target\", axis=1)  # Correct column name\n",
    "y = housing_df[\"Target\"]  # Median house price in $100,000s\n",
    "\n",
    "# Split into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# Instantiate and fit the model (on the training set)\n",
    "model = Ridge()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Check the score of the model on the test set\n",
    "score = model.score(x_test, y_test)\n",
    "print(f\"Model score on the test set: {score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8871a8c8-18c3-4879-bfb7-1ee9061e94fc",
   "metadata": {},
   "source": [
    "### This code is a complete pipeline for training and evaluating a **Ridge Regression model** using the **California Housing dataset**. Here's an explanation of each part:\n",
    "\n",
    "---\n",
    "\n",
    "### **Code Breakdown**\n",
    "\n",
    "#### 1. **Importing Libraries**\n",
    "```python\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "```\n",
    "- **`numpy`**: Used to set a random seed for reproducibility.\n",
    "- **`train_test_split`**: A function from `sklearn` to split the dataset into training and testing sets.\n",
    "- **`Ridge`**: A type of linear regression model that adds regularization to reduce overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Setting the Random Seed**\n",
    "```python\n",
    "np.random.seed(42)\n",
    "```\n",
    "- Ensures consistent results across runs by fixing the random number generation.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Preparing the Data**\n",
    "```python\n",
    "x = housing_df.drop(\"Target\", axis=1)  # Features (input data)\n",
    "y = housing_df[\"Target\"]              # Labels (output data)\n",
    "```\n",
    "- **`x`**: The input data, which includes all columns except the `\"Target\"` column.\n",
    "- **`y`**: The target variable, representing the median house prices (in $100,000s).\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **Splitting the Data**\n",
    "```python\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "```\n",
    "- Divides the dataset into **training** (80%) and **testing** (20%) subsets.\n",
    "  - **`x_train` and `y_train`**: Used to train the model.\n",
    "  - **`x_test` and `y_test`**: Used to evaluate the model's performance.\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. **Instantiating the Ridge Regression Model**\n",
    "```python\n",
    "model = Ridge()\n",
    "```\n",
    "- Creates an instance of the Ridge Regression model.\n",
    "- Ridge regression adds a **regularization term** to penalize large coefficients, making the model less likely to overfit.\n",
    "\n",
    "---\n",
    "\n",
    "#### 6. **Fitting the Model**\n",
    "```python\n",
    "model.fit(x_train, y_train)\n",
    "```\n",
    "- Trains the Ridge Regression model using the **training data** (`x_train` and `y_train`).\n",
    "- The model learns the relationships between the features and the target variable.\n",
    "\n",
    "---\n",
    "\n",
    "#### 7. **Evaluating the Model**\n",
    "```python\n",
    "score = model.score(x_test, y_test)\n",
    "```\n",
    "- Computes the **R² score** (coefficient of determination) of the model on the test set:\n",
    "  - \\( R^2 = 1 - \\frac{\\text{Sum of squared errors of predictions}}{\\text{Total sum of squares (variance of target)}} \\)\n",
    "- **R² Score**:\n",
    "  - \\( R^2 = 1 \\): Perfect prediction.\n",
    "  - \\( R^2 = 0 \\): Model predicts no better than the mean.\n",
    "  - \\( R^2 < 0 \\): Model performs worse than the mean.\n",
    "\n",
    "---\n",
    "\n",
    "#### 8. **Displaying the Model's Score**\n",
    "```python\n",
    "print(f\"Model score on the test set: {score}\")\n",
    "```\n",
    "- Prints the **R² score** for the test set, indicating how well the model generalizes to unseen data.\n",
    "\n",
    "---\n",
    "\n",
    "### **What Does This Code Do Overall?**\n",
    "1. Prepares the data for a **supervised learning task**.\n",
    "2. Splits the data into **training** and **testing** sets.\n",
    "3. Trains a **Ridge Regression model** using the training set.\n",
    "4. Evaluates the model's **performance** on the test set using the R² score.\n",
    "5. Prints the R² score as the evaluation metric.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example Output**\n",
    "If the R² score is `0.6016`, it means:\n",
    "- The model explains ~60.16% of the variance in the target variable on the test set.\n",
    "- The remaining ~39.84% is unexplained by the model.\n",
    "\n",
    "---\n",
    "\n",
    "Let me know if you'd like further clarification!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873ac4a9-70cc-4b40-86bf-fef6a030559b",
   "metadata": {},
   "source": [
    "What if Rdige  did not work or the scoer did not fit opur needs ?\n",
    "\n",
    "Well, we could always try a different model....\n",
    "\n",
    "How about we try an ensemble model (an ensemble is combination of smaller models to than just a single model) ?\n",
    "\n",
    "sklearn , ensemble model can be found here...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ea2f7f-39e2-4d25-a615-9a51f3415e2c",
   "metadata": {},
   "source": [
    "## Import the Randdom\\ForestRegressor model class from the ensemble module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7206b154-65ab-4352-b3a8-65a64a550781",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "x = housing_df.drop(\"Target\", axis=1)  # Correct column name\n",
    "y = housing_df[\"Target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)  # Fixed typo in function name\n",
    "\n",
    "# Create random forest model\n",
    "model = RandomForestRegressor()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Check the score of the model on the test set\n",
    "score = model.score(x_test, y_test)\n",
    "print(f\"Model score on the test set: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11147248-be34-491d-8172-5f093e92fa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Setup random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Assuming housing_df is already created, check its structure\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(housing_df.head())\n",
    "\n",
    "# Prepare the data\n",
    "x = housing_df.drop(\"Target\", axis=1)  # Features (input data)\n",
    "y = housing_df[\"Target\"]              # Labels (output data)\n",
    "\n",
    "# Display features and target preview\n",
    "print(\"\\nFeatures (x):\")\n",
    "print(x.head())\n",
    "\n",
    "print(\"\\nTarget (y):\")\n",
    "print(y.head())\n",
    "\n",
    "# Split into training and testing datasets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display train-test split sizes\n",
    "print(f\"\\nTrain size: {x_train.shape}, Test size: {x_test.shape}\")\n",
    "\n",
    "# Create and train the Random Forest Regressor model\n",
    "print(\"\\nTraining the Random Forest model...\")\n",
    "model = RandomForestRegressor()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "score = model.score(x_test, y_test)\n",
    "\n",
    "# Output the model's R² score\n",
    "print(f\"\\nModel score on the test set (R²): {score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b1ce62-2768-40c0-85c6-03507dd23476",
   "metadata": {},
   "source": [
    "### This code is a workflow for building and evaluating a machine learning model using a **Random Forest Regressor** from the `sklearn` library. Here’s a detailed explanation of each part:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Import Required Libraries**\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "```\n",
    "- **`RandomForestRegressor`**: A machine learning algorithm for regression tasks that builds multiple decision trees and averages their predictions for better accuracy and to avoid overfitting.\n",
    "- **`train_test_split`**: A utility to split the dataset into training and testing subsets.\n",
    "- **`numpy`**: A library for numerical operations, used here to set a random seed.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Set Random Seed**\n",
    "```python\n",
    "np.random.seed(42)\n",
    "```\n",
    "- Ensures reproducibility by setting a seed for random number generation. This ensures the data split and any random processes in the model yield the same result every time the code is run.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Create the Data**\n",
    "```python\n",
    "x = housing_df.drop(\"Target\", axis=1)  # Features (independent variables)\n",
    "y = housing_df[\"Target\"]              # Labels (dependent variable)\n",
    "```\n",
    "- **`x`**: Contains the feature columns used to predict the target variable (e.g., `MedInc`, `HouseAge`, etc.).\n",
    "- **`y`**: The target column (e.g., house prices).\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Split into Train and Test Sets**\n",
    "```python\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "```\n",
    "- Splits the data into:\n",
    "  - **`x_train` & `y_train`**: Used to train the model.\n",
    "  - **`x_test` & `y_test`**: Used to evaluate the model.\n",
    "- **`test_size=0.2`**: 20% of the data is reserved for testing, while 80% is used for training.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Create and Train the Model**\n",
    "```python\n",
    "model = RandomForestRegressor()\n",
    "model.fit(x_train, y_train)\n",
    "```\n",
    "- **`RandomForestRegressor()`**: Initializes the Random Forest model with default hyperparameters.\n",
    "- **`.fit(x_train, y_train)`**: Trains the model using the training dataset by learning patterns in the features (`x_train`) to predict the target values (`y_train`).\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Evaluate the Model**\n",
    "```python\n",
    "score = model.score(x_test, y_test)\n",
    "print(f\"Model score on the test set: {score}\")\n",
    "```\n",
    "- **`.score(x_test, y_test)`**:\n",
    "  - Computes the **R² score** on the test data.\n",
    "  - The R² score measures how well the model's predictions match the actual values.\n",
    "  - A score of:\n",
    "    - **1.0**: Perfect predictions.\n",
    "    - **0.0**: No predictive power (same as predicting the mean of the target variable).\n",
    "    - **< 0.0**: Worse than predicting the mean.\n",
    "\n",
    "---\n",
    "\n",
    "### **Purpose of Each Step**\n",
    "1. **Prepare the Data**: Select features (`x`) and target (`y`).\n",
    "2. **Split Data**: Train-test split ensures the model is evaluated on unseen data.\n",
    "3. **Train the Model**: Fit the Random Forest to learn from training data.\n",
    "4. **Evaluate the Model**: Use test data to measure how well the model generalizes.\n",
    "\n",
    "---\n",
    "\n",
    "### **Output Example**\n",
    "```plaintext\n",
    "Model score on the test set: 0.8262661624040282\n",
    "```\n",
    "This means the model explains approximately **82.63% of the variance** in the house prices, which indicates good performance.\n",
    "\n",
    "---\n",
    "\n",
    "### **Applications**\n",
    "- **Predictive Analytics**: Use the trained model to predict house prices for new, unseen data.\n",
    "- **Feature Importance**: Analyze which features have the most impact on predictions (e.g., `MedInc` might be most important).\n",
    "\n",
    "Let me know if you need further clarification or enhancements to this workflow!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95268aad-fef7-4682-8fca-6a2586908ecf",
   "metadata": {},
   "source": [
    "### Choosing an algorithum/estimator for a classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c487952-d8c6-4256-9d89-7b88c4ee2c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease = pd.read_csv(\"heart-disease.csv\")\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c52e6cf-a060-488d-93fe-75dd335f392f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(heart_disease)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339a8b0b-5d3e-4d25-bb07-99a7a68197db",
   "metadata": {},
   "source": [
    "### Condtion 1: True  ---- Samples are more than 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8983d97-de24-4279-a8df-bca629657393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing thr linearSVC estimator class\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed()\n",
    "\n",
    "# Make the data\n",
    "x = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_test=0.2)\n",
    "\n",
    "# Instantriate LinearSVC\n",
    "clf = LinearSVC()\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate the LinearSVC\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9210c2e7-b251-4e03-ab45-ca4c212b6549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer  # Using a built-in dataset as an example\n",
    "\n",
    "# Setup random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load the data\n",
    "#data = load_breast_cancer()  # Replace with your actual dataset if available\n",
    "x = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate LinearSVC with a specified max_iter to avoid convergence warnings\n",
    "clf = LinearSVC(max_iter=10000)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate the LinearSVC\n",
    "score = clf.score(x_test, y_test)\n",
    "print(f\"Model Accuracy: {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca141caa-42f8-464b-8a2d-db5a6c711da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc246f3e-936c-4a9f-b519-52d2a7710160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the RandomForestClassifier estimator class\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer  # Using a built-in dataset as an example\n",
    "\n",
    "# Setup random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load the data (using a built-in dataset as an example)\n",
    "data = load_breast_cancer()\n",
    "x = data.data  # Features\n",
    "y = data.target  # Target\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate Random Forest Classifier\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate the Random Forest Classifier\n",
    "score = clf.score(x_test, y_test)\n",
    "print(f\"Model Accuracy: {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c0c3ee-9689-4685-aaa8-0697973fd36a",
   "metadata": {},
   "source": [
    "Tidbit:\n",
    "\n",
    "    1. If you have structured data, use ensemble method.\n",
    "    2. If you have unstructured data, use deep learning or transfer learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435f4901-5962-4e42-a850-7faaec139e6a",
   "metadata": {},
   "source": [
    "## 3. Fit the Model/Algorithum on our data and use it to make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552be07e-db4d-48dc-a34b-b9fb44710715",
   "metadata": {},
   "source": [
    "### Fitting the model to the data\n",
    "\n",
    "Different names for: \n",
    "\n",
    "* 'x' = features, features variables, data\n",
    "* 'y' = labels, targets, target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff5b31e-832f-45f3-ac30-8e24b03477c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the RandomForestClassifier estimator class\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer  # Using a built-in dataset as an example\n",
    "\n",
    "# Setup random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load the data (using a built-in dataset as an example)\n",
    "data = load_breast_cancer()\n",
    "x = data.data  # Features\n",
    "y = data.target  # Target\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate Random Forest Classifier\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Fit the model tyo the data\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate the Random Forest Classifier\n",
    "score = clf.score(x_test, y_test)\n",
    "print(f\"Model Accuracy: {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8664206c-13b4-4a50-9127-b9ede53bb508",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e56b556-a79e-4433-bcfa-5956000a80fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the RandomForestClassifier estimator class\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer  # Using a built-in dataset as an example\n",
    "\n",
    "# Setup random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load the data (using a built-in dataset as an example)\n",
    "data = load_breast_cancer()\n",
    "x = data.data  # Features\n",
    "y = data.target  # Target\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate Random Forest Classifier\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Fit the model to the data\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate the Random Forest Classifier\n",
    "score = clf.score(x_test, y_test)\n",
    "print(f\"Model Accuracy: {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edbc77d-dff3-4916-b081-d86875b1d9f3",
   "metadata": {},
   "source": [
    "## Make Predictions Using Machine Learning Model\n",
    "\n",
    "2 Ways to make predictions:\n",
    "\n",
    "1. predict()\n",
    "2. predict_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34886a07-717e-4f37-81c9-99e077f3e1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a trained model to make predictions\n",
    "clf.predict(np.array([1,7,8,3,4])  # this does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d606844a-ac3c-46e6-bcbe-5ed57f4a67e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c8b0a0-ea45-4109-9b8d-e61dbed11289",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75bbdb1-aed7-40eb-bb96-4658ac65323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the RandomForestClassifier estimator class\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer  # Using a built-in dataset as an example\n",
    "\n",
    "# Setup random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load the data (using a built-in dataset as an example)\n",
    "data = load_breast_cancer()\n",
    "x = data.data  # Features\n",
    "y = data.target  # Target\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate Random Forest Classifier\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Fit the model to the data\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = clf.predict(x_test)\n",
    "\n",
    "# Display predictions\n",
    "print(\"Predictions:\", predictions)\n",
    "\n",
    "# Evaluate the Random Forest Classifier\n",
    "score = clf.score(x_test, y_test)\n",
    "print(f\"Model Accuracy: {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cb77ba-ae20-4c16-b8b6-8c15b7c14abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf75abf-8738-4552-8218-284cb8df0c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56477f37-1480-46f1-9661-0b7b6aec6abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95146cd-64bf-4ff5-84c9-36aa4852cf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare predictions to truth labels to evaluate the model\n",
    "y_preds = clf.predict(x_test)\n",
    "np.mean(y_preds == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bd1da1-4cc5-4c9d-b516-1c6599e21da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65296f65-9125-4d0a-9e76-6a1675aa8879",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,k y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c912c3-75bd-460e-a3a3-7194e6157df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "what_were_covering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1322916a-5a34-4b49-b4fc-c52b43b8d133",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming y_preds contains the predictions from clf.predict(x_test)\n",
    "y_preds = clf.predict(x_test)\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy = accuracy_score(y_test, y_preds)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ea7aff-fde5-4ba1-8198-f5315b2ab7a7",
   "metadata": {},
   "source": [
    "### Here's an explanation of the provided code snippet:\n",
    "\n",
    "---\n",
    "\n",
    "### **Code Breakdown:**\n",
    "\n",
    "1. **`from sklearn.metrics import accuracy_score`**\n",
    "   - This line imports the `accuracy_score` function from `sklearn.metrics`.  \n",
    "   - `accuracy_score` calculates the accuracy of a classification model, which is the proportion of correctly predicted labels out of the total number of predictions.\n",
    "\n",
    "---\n",
    "\n",
    "2. **`y_preds = clf.predict(x_test)`**\n",
    "   - This line uses the trained classifier (`clf`) to make predictions on the test data (`x_test`).\n",
    "   - The `.predict()` method generates a list or array of predicted labels (`y_preds`) based on the input features in `x_test`.\n",
    "\n",
    "---\n",
    "\n",
    "3. **`accuracy = accuracy_score(y_test, y_preds)`**\n",
    "   - This line calculates the accuracy of the model's predictions by comparing the predicted labels (`y_preds`) with the actual labels (`y_test`).\n",
    "   - Formula for accuracy:\n",
    "     \\[\n",
    "     \\text{Accuracy} = \\frac{\\text{Number of Correct Predictions}}{\\text{Total Number of Predictions}}\n",
    "     \\]\n",
    "   - For example:\n",
    "     - If `y_test = [0, 1, 1, 0]` and `y_preds = [0, 1, 0, 0]`, then the number of correct predictions is 3 (positions 0, 1, and 3 match).\n",
    "     - Accuracy = \\( \\frac{3}{4} = 0.75 \\).\n",
    "\n",
    "---\n",
    "\n",
    "4. **`print(f\"Model Accuracy: {accuracy:.2f}\")`**\n",
    "   - This prints the accuracy to the console, formatted to 2 decimal places.\n",
    "   - Example output: `\"Model Accuracy: 0.95\"` if the accuracy is 95%.\n",
    "\n",
    "---\n",
    "\n",
    "### **Purpose:**\n",
    "The code evaluates how well the trained model performs on the test dataset by comparing predicted outcomes (`y_preds`) to the actual outcomes (`y_test`). This is an essential step in model evaluation to gauge its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893c3edb-5e3e-48a7-96c3-47ec602f0678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming y_preds contains the predictions from clf.predict(x_test)\n",
    "y_preds = clf.predict(x_test)\n",
    "\n",
    "# Total number of predictions\n",
    "total_predictions = len(y_preds)\n",
    "print(f\"Total Number of Predictions: {total_predictions}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbb783a-bea8-4a9c-83c9-3b0200419462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming y_preds contains the predictions and y_test contains the true labels\n",
    "y_preds = clf.predict(x_test)\n",
    "\n",
    "# Count the number of correct predictions\n",
    "correct_predictions = sum(y_preds == y_test)  # Matches between y_preds and y_test\n",
    "print(f\"Number of Correct Predictions: {correct_predictions}\")\n",
    "\n",
    "# Alternative using accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_preds)\n",
    "correct_predictions_alt = int(accuracy * len(y_test))  # Calculate directly from accuracy\n",
    "print(f\"Number of Correct Predictions (Alternative): {correct_predictions_alt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d42363d-fce7-48e8-bd3d-88ffaaa40302",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# Assuming X is defined and has at least 36000 elements\n",
    "your_digit = X[36000]  # Extract the digit at index 36000\n",
    "\n",
    "# Reshape the digit (ensure dimensions are correct, commonly 28x28)\n",
    "your_image = your_digit.reshape(28, 28)\n",
    "\n",
    "# Plot the image\n",
    "plt.imshow(your_image, cmap=matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f0213a-0a6c-4a5f-9b6c-d115fc1a9aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.datasets import fetch_openml  # For loading the MNIST dataset\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X = mnist.data  # Features (image pixel data)\n",
    "\n",
    "# Extract the 36000th digit\n",
    "your_digit = X.iloc[36000]  # Use .iloc for DataFrame access\n",
    "\n",
    "# Reshape the digit into a 28x28 image\n",
    "your_image = your_digit.values.reshape(28, 28)\n",
    "\n",
    "# Plot the image\n",
    "plt.imshow(your_image, cmap=matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb3a768-001f-427b-9ff2-d0c99e9ca277",
   "metadata": {},
   "source": [
    "## Make Prediction With Predict_Proba()\n",
    "\n",
    "Predict_Proba() returns probabilities of classification label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff05e0aa-d196-4ba3-9290-3d4a0857db6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f973dae7-4550-4513-91bf-1331f46db426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Instantiate LinearSVC\n",
    "base_clf = LinearSVC(max_iter=10000)\n",
    "\n",
    "# Wrap with CalibratedClassifierCV\n",
    "clf = CalibratedClassifierCV(base_clf, cv=5)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "probabilities = clf.predict_proba(x_test)\n",
    "print(probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ff86cb-0a13-499d-bf61-01e0f5490f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf.predict_proba(x_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11eb4fc-877b-42fa-b359-40a771eb6523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's Predict() On The Same Data\n",
    "\n",
    "clf.predict(x_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57067359-484d-4f5b-9dca-fe33fd38ce83",
   "metadata": {},
   "source": [
    "# Let's Predict() On The Same Data\n",
    "\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea1390c-f065-4fbc-998f-963c3d50becc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's Predict() On The Same Data\n",
    "\n",
    "clf.predict(x_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d26f73-eacd-4203-969d-b9582f047a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease[\"target\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d62ae5-7e52-4c30-9af5-a92f4d60421d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c086ecc8-4388-4249-a334-b8d7cd01ee23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1be64d-e2c1-423f-b9ea-027f3d8cb8a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc5d372-7db6-4055-b48f-7f5428298f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install libraries (use pip if not installed)\n",
    "# pip install pandas numpy matplotlib scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Step 2: Load the data\n",
    "# Replace 'heart-disease.csv' with your actual CSV file name\n",
    "data = pd.read_csv('heart-disease.csv')\n",
    "\n",
    "# Step 3: Explore the data\n",
    "print(data.head())  # Show the first few rows\n",
    "print(data.info())  # Check data types and missing values\n",
    "\n",
    "# Step 4: Handle missing values (if any)\n",
    "data.fillna(data.mean(), inplace=True)  # Fill missing values with column mean\n",
    "\n",
    "# Step 5: Separate features and labels\n",
    "x = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]              # Target variable (1 or 0)\n",
    "\n",
    "# Step 6: Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 7: Choose and train a model\n",
    "model = RandomForestClassifier(random_state=42)  # Use Random Forest algorithm\n",
    "model.fit(X_train, y_train)  # Train the model\n",
    "\n",
    "# Step 8: Evaluate the model\n",
    "y_pred = model.predict(X_test)  # Make predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)  # Calculate accuracy\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Step 9: Make predictions\n",
    "# Example new data (ensure the structure matches the training data features)\n",
    "new_data = pd.DataFrame(\n",
    "    [[57, 1, 130, 245, 1, 1, 120, 1]],  # Example row\n",
    "    columns=X.columns                   # Match column names to the training data\n",
    ")\n",
    "\n",
    "# Predict on new data\n",
    "prediction = model.predict(new_data)\n",
    "print(\"Heart Disease Prediction:\", \"Yes\" if prediction[0] == 1 else \"No\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5816d69-0f99-4490-9ea9-e08f68fbb9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc0fbcc-7383-48e2-880a-2d2385a25b13",
   "metadata": {},
   "source": [
    "## Heart Disease (YES OR NO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c61aed-0a95-489f-b025-43387aa15e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Step 1: Load the data\n",
    "data = pd.read_csv('heart-disease.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Step 2: Explore the data\n",
    "print(data.head())  # Display the first few rows of the dataset\n",
    "print(data.info())  # Display information about columns and data types\n",
    "\n",
    "# Step 3: Handle missing values (if any)\n",
    "data.fillna(data.mean(), inplace=True)  # Replace missing values with column mean\n",
    "\n",
    "# Step 4: Separate features and labels\n",
    "# Ensure the correct column names are used from the dataset\n",
    "features = data.drop('target', axis=1)  # Drop the target column to get features\n",
    "labels = data['target']                # Target variable (1 or 0)\n",
    "\n",
    "# Step 5: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Train the model\n",
    "model = RandomForestClassifier(random_state=42)  # Initialize Random Forest Classifier\n",
    "model.fit(X_train, y_train)                      # Train the model on training data\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "y_pred = model.predict(X_test)                   # Make predictions on test data\n",
    "accuracy = accuracy_score(y_test, y_pred)       # Calculate accuracy\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Step 8: Make predictions\n",
    "# Example new data (ensure the structure matches the training data features)\n",
    "new_data = pd.DataFrame(\n",
    "    [[57, 1, 130, 245, 1, 1, 120, 1]],  # Example data row (modify as needed)\n",
    "    columns=features.columns            # Ensure the column names match\n",
    ")\n",
    "\n",
    "# Predict on new data\n",
    "prediction = model.predict(new_data)\n",
    "print(\"Heart Disease Prediction:\", \"Yes\" if prediction[0] == 1 else \"No\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54128c6f-8e7e-4272-b3e5-1639e58a1ebb",
   "metadata": {},
   "source": [
    "## Heart Disease (YES OR NO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3082c169-783e-41ef-8888-6da91c3a2639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Step 1: Load the data\n",
    "data = pd.read_csv('heart-disease.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Step 2: Explore the data\n",
    "print(data.head())  # Display the first few rows of the dataset\n",
    "print(data.info())  # Display information about columns and data types\n",
    "\n",
    "# Step 3: Handle missing values (if any)\n",
    "data.fillna(data.mean(), inplace=True)  # Replace missing values with column mean\n",
    "\n",
    "# Step 4: Separate features and labels\n",
    "# Ensure the correct column names are used from the dataset\n",
    "features = data.drop('target', axis=1)  # Drop the target column to get features\n",
    "labels = data['target']                # Target variable (1 or 0)\n",
    "\n",
    "# Step 5: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Train the model\n",
    "model = RandomForestClassifier(random_state=42)  # Initialize Random Forest Classifier\n",
    "model.fit(X_train, y_train)                      # Train the model on training data\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "y_pred = model.predict(X_test)                   # Make predictions on test data\n",
    "accuracy = accuracy_score(y_test, y_pred)       # Calculate accuracy\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Step 8: Make predictions\n",
    "# Example new data (ensure the structure matches the training data features)\n",
    "new_data = pd.DataFrame(\n",
    "    [[57, 1, 130, 245, 1, 1, 120, 1, 0, 1, 1, 2, 3]],  # Example data row (modify as needed)\n",
    "    columns=features.columns            # Ensure the column names match\n",
    ")\n",
    "\n",
    "# Predict on new data\n",
    "prediction = model.predict(new_data)\n",
    "print(\"Heart Disease Prediction:\", \"Yes\" if prediction[0] == 1 else \"No\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9af9842-e13d-4efb-ac67-5eeb3471090a",
   "metadata": {},
   "source": [
    "## Heart Disease (YES OR NO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb75698f-df32-4270-9cb3-feda2c582501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Step 1: Load the data\n",
    "data = pd.read_csv('modified_heart_disease.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Step 2: Explore the data\n",
    "print(data.head())  # Display the first few rows of the dataset\n",
    "print(data.info())  # Display information about columns and data types\n",
    "\n",
    "# Step 3: Handle missing values (if any)\n",
    "data.fillna(data.mean(), inplace=True)  # Replace missing values with column mean\n",
    "\n",
    "# Step 4: Separate features and labels\n",
    "# Ensure the correct column names are used from the dataset\n",
    "features = data.drop('target', axis=1)  # Drop the target column to get features\n",
    "labels = data['target']                # Target variable (1 or 0)\n",
    "\n",
    "# Step 5: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Train the model\n",
    "model = RandomForestClassifier(random_state=42)  # Initialize Random Forest Classifier\n",
    "model.fit(X_train, y_train)                      # Train the model on training data\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "y_pred = model.predict(X_test)                   # Make predictions on test data\n",
    "accuracy = accuracy_score(y_test, y_pred)       # Calculate accuracy\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Step 8: Make predictions\n",
    "# Example new data (ensure the structure matches the training data features)\n",
    "new_data = pd.DataFrame(\n",
    "    [[57, 1, 130, 245, 1, 1, 120, 1, 0, 1, 1, 2, 3]],  # Example data row (modify as needed)\n",
    "    columns=features.columns            # Ensure the column names match\n",
    ")\n",
    "\n",
    "# Predict on new data\n",
    "prediction = model.predict(new_data)\n",
    "print(\"Heart Disease Prediction:\", \"Yes\" if prediction[0] == 1 else \"No\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d659c3bb-480f-4215-9dcd-ef43e05f00a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fdec48-044b-471a-a6a8-60a89bb8431b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'College_Report_Card - Copy.csv'  # Path to the file\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"Dataset Preview:\")\n",
    "print(data.head())\n",
    "\n",
    "# Check for missing values and handle them\n",
    "if data.isnull().sum().any():\n",
    "    print(\"\\nHandling missing values...\")\n",
    "    data = data.fillna(data.mean())  # Replace missing values with column means\n",
    "\n",
    "# Define the threshold for 'performed very well'\n",
    "threshold = 90  # Adjust as needed\n",
    "\n",
    "# Identify score-related columns (excluding non-score columns like 'StudentID' or 'Pass')\n",
    "score_columns = [col for col in data.columns if col not in ['StudentID', 'Name', 'Pass']]\n",
    "\n",
    "\n",
    "# Analyze performance for each course\n",
    "performance_summary = {}\n",
    "for course in score_columns:\n",
    "    avg_score = data[course].mean()\n",
    "    high_performance_count = (data[course] >= threshold).sum()\n",
    "    performance_summary[course] = {\n",
    "        'Average Score': avg_score,\n",
    "        'Students Scored Above Threshold': high_performance_count\n",
    "    }\n",
    "\n",
    "# Find the course with the best performance\n",
    "best_course = max(performance_summary, key=lambda x: performance_summary[x]['Students Scored Above Threshold'])\n",
    "\n",
    "# Output the performance summary\n",
    "print(\"\\nPerformance Summary:\")\n",
    "for course, stats in performance_summary.items():\n",
    "    print(f\"{course}: {stats}\")\n",
    "\n",
    "print(f\"\\nCourse with the best performance: {best_course}\")\n",
    "\n",
    "# Visualization\n",
    "course_names = list(performance_summary.keys())\n",
    "high_performance_counts = [performance_summary[course]['Students Scored Above Threshold'] for course in course_names]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(course_names, high_performance_counts, color='skyblue')\n",
    "plt.title('High Performers per Course')\n",
    "plt.xlabel('Courses')\n",
    "plt.ylabel('Number of Students Scoring Above Threshold')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5184d0-a481-4527-a58e-8d92129d8058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'College_Report_Card - Copy.csv'  # Path to the file\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"Dataset Preview:\")\n",
    "print(data.head())\n",
    "\n",
    "# Check for missing values and handle them\n",
    "if data.isnull().sum().any():\n",
    "    print(\"\\nHandling missing values...\")\n",
    "    # Fill missing values for numeric columns with the mean\n",
    "    numeric_cols = data.select_dtypes(include=['number']).columns\n",
    "    data[numeric_cols] = data[numeric_cols].fillna(data[numeric_cols].mean())\n",
    "    # Fill missing values for non-numeric columns (if needed)\n",
    "    non_numeric_cols = data.select_dtypes(exclude=['number']).columns\n",
    "    data[non_numeric_cols] = data[non_numeric_cols].fillna('Unknown')\n",
    "\n",
    "# Define the threshold for 'performed very well'\n",
    "threshold = 90  # Adjust as needed\n",
    "\n",
    "# Identify score-related columns (excluding non-score columns like 'StudentID' or 'Name')\n",
    "score_columns = [col for col in data.columns if col not i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1314d104-535f-4b4c-910f-0ad0292ff1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'College_Report_Card - Copy.csv'  # Path to the file\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"Dataset Preview:\")\n",
    "print(data.head())\n",
    "\n",
    "# Check for missing values and handle them\n",
    "if data.isnull().sum().any():\n",
    "    print(\"\\nHandling missing values...\")\n",
    "    # Fill missing values for numeric columns with the mean\n",
    "    numeric_cols = data.select_dtypes(include=['number']).columns\n",
    "    data[numeric_cols] = data[numeric_cols].fillna(data[numeric_cols].mean())\n",
    "    # Fill missing values for non-numeric columns (if needed)\n",
    "    non_numeric_cols = data.select_dtypes(exclude=['number']).columns\n",
    "    data[non_numeric_cols] = data[non_numeric_cols].fillna('Unknown')\n",
    "\n",
    "# Define the threshold for 'performed very well'\n",
    "threshold = 90  # Adjust as needed\n",
    "\n",
    "# Identify score-related columns (excluding non-score columns like 'StudentID' or 'Name')\n",
    "score_columns = [col for col in data.columns if col not in ['StudentID', 'Name', 'Pass']]\n",
    "\n",
    "# Analyze performance for each course\n",
    "performance_summary = {}\n",
    "for course in score_columns:\n",
    "    avg_score = data[course].mean()\n",
    "    high_performance_count = (data[course] >= threshold).sum()\n",
    "    performance_summary[course] = {\n",
    "        'Average Score': avg_score,\n",
    "        'Students Scored Above Threshold': high_performance_count\n",
    "    }\n",
    "\n",
    "# Find the course with the best performance\n",
    "best_course = max(performance_summary, key=lambda x: performance_summary[x]['Students Scored Above Threshold'])\n",
    "\n",
    "# Output the performance summary\n",
    "print(\"\\nPerformance Summary:\")\n",
    "for course, stats in performance_summary.items():\n",
    "    print(f\"{course}: {stats}\")\n",
    "\n",
    "print(f\"\\nCourse with the best performance: {best_course}\")\n",
    "\n",
    "# Visualization\n",
    "course_names = list(performance_summary.keys())\n",
    "high_performance_counts = [performance_summary[course]['Students Scored Above Threshold'] for course in course_names]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(course_names, high_performance_counts, color='skyblue')\n",
    "plt.title('High Performers per Course')\n",
    "plt.xlabel('Courses')\n",
    "plt.ylabel('Number of Students Scoring Above Threshold')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ee8846-3ad9-43f8-9e42-4ef64c88e800",
   "metadata": {},
   "source": [
    "## Heart Disease (YES OR NO): Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa15d16-c9ad-4c22-8a7d-c172baf2a980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Step 1: Load the data\n",
    "data = pd.read_csv('modified_heart_disease.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Step 2: Explore the data\n",
    "print(data.head())  # Display the first few rows of the dataset\n",
    "print(data.info())  # Display information about columns and data types\n",
    "\n",
    "# Step 3: Handle missing values (if any)\n",
    "data.fillna(data.mean(), inplace=True)  # Replace missing values with column mean\n",
    "\n",
    "# Step 4: Separate features and labels\n",
    "# Ensure the correct column names are used from the dataset\n",
    "features = data.drop('target', axis=1)  # Drop the target column to get features\n",
    "labels = data['target']                # Target variable (1 or 0)\n",
    "\n",
    "# Step 5: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Train the model using Logistic Regression\n",
    "model = LogisticRegression(random_state=42, max_iter=1000)  # Initialize Logistic Regression model\n",
    "model.fit(X_train, y_train)                                # Train the model on training data\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "y_pred = model.predict(X_test)                   # Make predictions on test data\n",
    "accuracy = accuracy_score(y_test, y_pred)       # Calculate accuracy\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Step 8: Make predictions\n",
    "# Example new data (ensure the structure matches the training data features)\n",
    "new_data = pd.DataFrame(\n",
    "    [[57, 1, 130, 245, 1, 1, 120, 1, 0, 1, 1, 2, 3]],  # Example data row (modify as needed)\n",
    "    columns=features.columns            # Ensure the column names match\n",
    ")\n",
    "\n",
    "# Predict on new data\n",
    "prediction = model.predict(new_data)\n",
    "print(\"Heart Disease Prediction:\", \"Yes\" if prediction[0] == 1 else \"No\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614e5d90-31f2-42b7-a67c-35b41899c5dd",
   "metadata": {},
   "source": [
    "|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e58bd45-4d7d-40f8-ac6e-d6d97d0635a7",
   "metadata": {},
   "source": [
    "## Heart Disease (YES OR NO): Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a168e15-4e5e-4af2-868a-21093348b569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Step 1: Load the data\n",
    "data = pd.read_csv('modified_heart_disease.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Step 2: Explore the data\n",
    "print(data.head())  # Display the first few rows of the dataset\n",
    "print(data.info())  # Display information about columns and data types\n",
    "\n",
    "# Step 3: Handle missing values (if any)\n",
    "data.fillna(data.mean(), inplace=True)  # Replace missing values with column mean\n",
    "\n",
    "# Step 4: Separate features and labels\n",
    "# Ensure the correct column names are used from the dataset\n",
    "features = data.drop('target', axis=1)  # Drop the target column to get features\n",
    "labels = data['target']                # Target variable (1 or 0)\n",
    "\n",
    "# Step 5: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Train the model\n",
    "model = RandomForestClassifier(random_state=42)  # Initialize Random Forest Classifier\n",
    "model.fit(X_train, y_train)                      # Train the model on training data\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "y_pred = model.predict(X_test)                   # Make predictions on test data\n",
    "accuracy = accuracy_score(y_test, y_pred)       # Calculate accuracy\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Step 8: Make predictions\n",
    "# Example new data (ensure the structure matches the training data features)\n",
    "new_data = pd.DataFrame(\n",
    "    [[57, 1, 130, 245, 1, 1, 120, 1, 0, 1, 1, 2, 3]],  # Example data row (modify as needed)\n",
    "    columns=features.columns            # Ensure the column names match\n",
    ")\n",
    "\n",
    "# Predict on new data\n",
    "prediction = model.predict(new_data)\n",
    "print(\"Heart Disease Prediction:\", \"Yes\" if prediction[0] == 1 else \"No\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9c2f3e-406e-45b3-a43f-1cae7499fe66",
   "metadata": {},
   "source": [
    "## Heart Disease (YES OR NO): Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f78841-0825-4a9c-b2e6-df1093d705c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Step 1: Load the data\n",
    "data = pd.read_csv('modified_heart_disease.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Step 2: Explore the data\n",
    "print(data.head())  # Display the first few rows of the dataset\n",
    "print(data.info())  # Display information about columns and data types\n",
    "\n",
    "# Step 3: Handle missing values (if any)\n",
    "data.fillna(data.mean(), inplace=True)  # Replace missing values with column mean\n",
    "\n",
    "# Step 4: Separate features and labels\n",
    "# Ensure the correct column names are used from the dataset\n",
    "features = data.drop('target', axis=1)  # Drop the target column to get features\n",
    "labels = data['target']                # Target variable (1 or 0)\n",
    "\n",
    "# Step 5: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Train the model using Support Vector Machines (SVM)\n",
    "model = SVC(kernel='linear', random_state=42)  # Initialize SVM model with a linear kernel\n",
    "model.fit(X_train, y_train)                   # Train the model on training data\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "y_pred = model.predict(X_test)                   # Make predictions on test data\n",
    "accuracy = accuracy_score(y_test, y_pred)       # Calculate accuracy\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Step 8: Make predictions\n",
    "# Example new data (ensure the structure matches the training data features)\n",
    "new_data = pd.DataFrame(\n",
    "    [[57, 1, 130, 245, 1, 1, 120, 1, 0, 1, 1, 2, 3]],  # Example data row (modify as needed)\n",
    "    columns=features.columns            # Ensure the column names match\n",
    ")\n",
    "\n",
    "# Predict on new data\n",
    "prediction = model.predict(new_data)\n",
    "print(\"Heart Disease Prediction:\", \"Yes\" if prediction[0] == 1 else \"No\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc7c3d5-9991-43fd-8a1f-633a6e3fec8b",
   "metadata": {},
   "source": [
    "## Heart Disease (YES OR NO): K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc582ba-d549-4561-b69c-2fce2a253cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Step 1: Load the data\n",
    "data = pd.read_csv('modified_heart_disease.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Step 2: Explore the data\n",
    "print(data.head())  # Display the first few rows of the dataset\n",
    "print(data.info())  # Display information about columns and data types\n",
    "\n",
    "# Step 3: Handle missing values (if any)\n",
    "data.fillna(data.mean(), inplace=True)  # Replace missing values with column mean\n",
    "\n",
    "# Step 4: Separate features and labels\n",
    "# Ensure the correct column names are used from the dataset\n",
    "features = data.drop('target', axis=1)  # Drop the target column to get features\n",
    "labels = data['target']                # Target variable (1 or 0)\n",
    "\n",
    "# Step 5: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Train the model using K-Nearest Neighbors (KNN)\n",
    "model = KNeighborsClassifier(n_neighbors=5)  # Initialize KNN model with k=5 (default)\n",
    "model.fit(X_train, y_train)                  # Train the model on training data\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "y_pred = model.predict(X_test)                   # Make predictions on test data\n",
    "accuracy = accuracy_score(y_test, y_pred)       # Calculate accuracy\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Step 8: Make predictions\n",
    "# Example new data (ensure the structure matches the training data features)\n",
    "new_data = pd.DataFrame(\n",
    "    [[57, 1, 130, 245, 1, 1, 120, 1, 0, 1, 1, 2, 3]],  # Example data row (modify as needed)\n",
    "    columns=features.columns            # Ensure the column names match\n",
    ")\n",
    "\n",
    "# Predict on new data\n",
    "prediction = model.predict(new_data)\n",
    "print(\"Heart Disease Prediction:\", \"Yes\" if prediction[0] == 1 else \"No\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c996ceb-76c7-44c4-9f9a-4edff51513fd",
   "metadata": {},
   "source": [
    "## Heart Disease (YES OR NO): Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9184d040-ba12-429e-805f-a6a6c4748cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Step 1: Load the data\n",
    "data = pd.read_csv('modified_heart_disease.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Step 2: Explore the data\n",
    "print(data.head())  # Display the first few rows of the dataset\n",
    "print(data.info())  # Display information about columns and data types\n",
    "\n",
    "# Step 3: Handle missing values (if any)\n",
    "data.fillna(data.mean(), inplace=True)  # Replace missing values with column mean\n",
    "\n",
    "# Step 4: Separate features and labels\n",
    "# Ensure the correct column names are used from the dataset\n",
    "features = data.drop('target', axis=1)  # Drop the target column to get features\n",
    "labels = data['target']                # Target variable (1 or 0)\n",
    "\n",
    "# Step 5: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Train the model using a Neural Network (MLPClassifier)\n",
    "model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)  # Initialize Neural Network\n",
    "model.fit(X_train, y_train)                                                      # Train the model on training data\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "y_pred = model.predict(X_test)                   # Make predictions on test data\n",
    "accuracy = accuracy_score(y_test, y_pred)       # Calculate accuracy\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Step 8: Make predictions\n",
    "# Example new data (ensure the structure matches the training data features)\n",
    "new_data = pd.DataFrame(\n",
    "    [[57, 1, 130, 245, 1, 1, 120, 1, 0, 1, 1, 2, 3]],  # Example data row (modify as needed)\n",
    "    columns=features.columns            # Ensure the column names match\n",
    ")\n",
    "\n",
    "# Predict on new data\n",
    "prediction = model.predict(new_data)\n",
    "print(\"Heart Disease Prediction:\", \"Yes\" if prediction[0] == 1 else \"No\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866bdb93-0b3f-4cfa-ba40-cce753826581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3451413a-e5bf-4e21-87b6-9976d80d6bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabb7b91-c367-41ef-87d1-6622ce2ff4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "\n",
    "x = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "# Split into training and test sets\n",
    "\n",
    "x_train, x_test, y_train, y_test = tarin_test_split(x,y, test_size=0.2)\n",
    "\n",
    "# Create model instance\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=2)\n",
    "\n",
    "# Fit the model to the data\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "\n",
    "#y_preds = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c81ec83-6ee8-4732-a126-c23d65a3c890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split  # Import the correct function for splitting data\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Assuming housing_df is a DataFrame with \"target\" as the column for prediction\n",
    "# Create the data\n",
    "x = housing_df.drop(\"target\", axis=1)  # Features\n",
    "y = housing_df[\"target\"]              # Target variable\n",
    "\n",
    "# Split into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a RandomForestRegressor model instance\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_preds = model.predict(x_test)\n",
    "\n",
    "# Print predictions (optional)\n",
    "print(y_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b726af71-ffd7-4413-8859-1dd1eef0415d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Assuming housing_df is a DataFrame with \"price\" as the target column\n",
    "x = housing_df.drop(\"price\", axis=1)  # Features\n",
    "y = housing_df[\"price\"]              # Target variable\n",
    "\n",
    "# Split into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a RandomForestRegressor model instance\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_preds = model.predict(x_test)\n",
    "\n",
    "# Print predictions (optional)\n",
    "print(y_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeb8ff2-615e-4bda-8ea4-b37551e4c3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "what_were_covering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df103d3-0ad7-461b-b211-83d4ad12e635",
   "metadata": {},
   "source": [
    "## 4. Evaluating a model\n",
    "\n",
    "There are three ways to evaluate scikit-learn models/estimators:\n",
    "\n",
    "1. Estimator's  built in score() method\n",
    "2. The Scoring Parameter\n",
    "3. Problem Specific Metric Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a7a03d-ac10-44bb-af6a-c2e566a98baa",
   "metadata": {},
   "source": [
    "### 4.1 Estimating a model with the score() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd514b2-5a8b-4401-adf4-7a286549e065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Make the data \n",
    "x = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split the data\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
    "\n",
    "# Instantiate Random Forest Classifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 1000)\n",
    "\n",
    "# Fit the model to the (training the machine learning model)\n",
    "\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0e7fb6-bd5d-4c18-81d5-6643aa4b770e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The highest value for the .score() method is 1.0, the lowest is 0.0\n",
    "\n",
    "clf.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdccbd1-1dfa-40ce-9218-9506f62536a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6654db-7358-4b0d-a4ad-76955b518c90",
   "metadata": {},
   "source": [
    "Let's use the 'score()' on our regression problem.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f990a2-34d5-4a43-975f-2d2e5ce746e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make the data \n",
    "x = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split the data\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
    "\n",
    "# Instantiate Random Forest Classifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "# Fit the model to the (training the machine learning model)\n",
    "\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcfe54f-e048-4196-bc99-652c3b923cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc01b0d-ec3f-444d-957e-3b6fe497ec45",
   "metadata": {},
   "source": [
    "### Evaluating the Model in Machine Learning\n",
    "Model evaluation is the process of assessing how well a machine learning model performs on unseen data. It helps determine the model's accuracy, reliability, and generalization capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b148f4d3-2cb4-43c7-b4a9-cccc03955ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example in Code (Classification Metrics):\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47ee424-7d93-4d08-a3d6-c6011029ef92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Sample Data (replace with your dataset)\n",
    "# Assume heart_disease is a pandas DataFrame\n",
    "# Replace 'target' with your actual target column name\n",
    "heart_disease = pd.read_csv(\"heart_disease_data.csv\")\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate the Model\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Define Custom Scoring (Optional: use predefined metrics for simplicity)\n",
    "custom_scorer = make_scorer(f1_score)\n",
    "\n",
    "# Cross-Validation with Scoring\n",
    "cv_scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')  # Using accuracy as scoring\n",
    "print(f\"Cross-Validation Accuracy Scores: {cv_scores}\")\n",
    "print(f\"Mean CV Accuracy: {cv_scores.mean()}\")\n",
    "\n",
    "# Train the Model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on Test Data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Final Evaluation Using a Scoring Metric\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Final Accuracy on Test Data: {accuracy}\")\n",
    "print(f\"Final F1 Score on Test Data: {f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71f9f24-3991-4f80-abeb-df34ab61d0f4",
   "metadata": {},
   "source": [
    "### 4.2.1 Classification Model Evaluation Metrics\n",
    "\n",
    "1. Accuracy\n",
    "2. Area Under ROC Curve\n",
    "3. Confusion Metrix\n",
    "4. Classifination Rport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20eb8eb5-34eb-4043-9e84-c0b3d52fe977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (replace with actual file path if needed)\n",
    "file_path = \"heart_disease_data.csv\"  # Adjust the path if required\n",
    "heart_disease = pd.read_csv(file_path)\n",
    "\n",
    "# Prepare the data\n",
    "X = heart_disease.drop(\"target\", axis=1)  # Features\n",
    "y = heart_disease[\"target\"]  # Target variable\n",
    "\n",
    "# Check class balance in the target variable\n",
    "print(\"Target class distribution:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# Split the data (using stratify to maintain class distribution)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train a RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate metrics\n",
    "# 1. Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# 2. Area Under ROC Curve (AUC) with a safety check\n",
    "if len(clf.classes_) > 1:  # Ensure at least two classes exist\n",
    "    y_prob = clf.predict_proba(X_test)[:, 1]  # Use probabilities for ROC AUC\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "    print(f\"Area Under ROC Curve (AUC): {roc_auc:.2f}\")\n",
    "else:\n",
    "    print(\"ROC AUC score cannot be calculated as there is only one class.\")\n",
    "\n",
    "# 3. Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# 4. Classification Report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f07af11-62e0-486b-9a63-6a3f18ff4d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "x = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# x_train, x_test, y_train, y_test\n",
    "\n",
    "clf = RandomForsetClassifier()\n",
    "cross_val_score(clf,x,y,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5950ffd-f73d-489a-97e6-b582634fc0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Prepare data\n",
    "x = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Instantiate the classifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(clf, x, y, cv=5)  # 5-fold cross-validation\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean accuracy:\", cv_scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1decfd-4764-4cc7-9957-7cba77ec8f52",
   "metadata": {},
   "source": [
    "### The output you received indicates that your model achieved perfect performance during cross-validation. Here's a detailed explanation:\n",
    "\n",
    "---\n",
    "\n",
    "### **Output Analysis**\n",
    "1. **Cross-Validation Scores**:\n",
    "   - `[1. 1. 1. 1. 1.]`: These are the accuracy scores for each of the 5 folds in the cross-validation process.\n",
    "   - A score of `1.0` in each fold means the model predicted all the test samples in each fold correctly.\n",
    "\n",
    "2. **Mean Accuracy**:\n",
    "   - `1.0`: This is the average of the cross-validation scores.\n",
    "   - Since all the fold scores are `1.0`, the mean accuracy is also `1.0`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Why Is This Happening?**\n",
    "1. **Perfect Performance**:\n",
    "   - This often indicates that the model has overfit the training data or the dataset is too small/simple, making it easy for the model to memorize the data.\n",
    "\n",
    "2. **Dataset Issues**:\n",
    "   - If the dataset is imbalanced or contains patterns that are too simple or repetitive, the model might find it easy to achieve perfect accuracy.\n",
    "\n",
    "3. **Cross-Validation Splitting**:\n",
    "   - If your dataset is small, stratified splitting may result in similar data distributions across all folds, which could lead to perfect scores.\n",
    "\n",
    "---\n",
    "\n",
    "### **Next Steps to Verify and Improve**\n",
    "1. **Check Dataset Size**:\n",
    "   - Print the shape of your dataset to ensure it is large enough for meaningful cross-validation:\n",
    "     ```python\n",
    "     print(x.shape, y.shape)\n",
    "     ```\n",
    "\n",
    "2. **Check Class Balance**:\n",
    "   - Ensure the target variable (`y`) has a balanced distribution:\n",
    "     ```python\n",
    "     print(y.value_counts())\n",
    "     ```\n",
    "\n",
    "3. **Evaluate on a Separate Test Set**:\n",
    "   - Cross-validation scores are useful but don't replace testing on unseen data.\n",
    "   - Split your data into training and testing sets and evaluate the model:\n",
    "     ```python\n",
    "     from sklearn.model_selection import train_test_split\n",
    "\n",
    "     X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)\n",
    "     clf.fit(X_train, y_train)\n",
    "     print(\"Test accuracy:\", clf.score(X_test, y_test))\n",
    "     ```\n",
    "\n",
    "4. **Experiment with Hyperparameters**:\n",
    "   - A RandomForestClassifier with default hyperparameters might overfit small datasets. Adjust parameters like `max_depth` or `n_estimators` to prevent overfitting:\n",
    "     ```python\n",
    "     clf = RandomForestClassifier(n_estimators=50, max_depth=5, random_state=42)\n",
    "     ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "While a perfect score might look impressive, it's often a sign that the evaluation setup or dataset requires closer inspection. By taking the steps above, you can verify the robustness of your model. Let me know if you need further help!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9197f7b-7ab6-4040-b715-e05133398a98",
   "metadata": {},
   "source": [
    "## Evaluating a Classification Model Using ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ad4634-3a2c-4e52-983d-b09e330609d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"heart_disease_data.csv\"  # Ensure this file is in your working directory\n",
    "heart_disease = pd.read_csv(file_path)\n",
    "\n",
    "# Prepare the data\n",
    "X = heart_disease.drop(\"target\", axis=1)  # Features\n",
    "y = heart_disease[\"target\"]  # Target variable\n",
    "\n",
    "# Ensure y is a 1D array\n",
    "y = y.ravel()\n",
    "\n",
    "# Check if y contains both classes\n",
    "if len(set(y)) < 2:\n",
    "    raise ValueError(\"Target variable 'y' must contain both classes (0 and 1) for binary classification.\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train the model\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions (probabilities)\n",
    "y_probs = clf.predict_proba(X_test)[:, 1]  # Get probabilities for the positive class (1)\n",
    "\n",
    "# Calculate the ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
    "\n",
    "# Calculate the AUC (Area Under Curve)\n",
    "roc_auc = roc_auc_score(y_test, y_probs)\n",
    "\n",
    "# Plot the ROC Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color=\"blue\", label=f\"ROC Curve (AUC = {roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], color=\"gray\", linestyle=\"--\", label=\"Random Guess\")\n",
    "plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "plt.ylabel(\"True Positive Rate (TPR)\")\n",
    "plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed6e220-c7e4-4419-96f2-126074a3b3c0",
   "metadata": {},
   "source": [
    "## Area Under The Operating Characteristic Curve (AUC/ROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c49166-e801-4f79-be24-8f748571a673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn,metrics import roc_curve\n",
    "\n",
    "# Make Predictions with probabilities\n",
    "\n",
    "y_probs = clf.predict_proba(x_test)\n",
    "\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b9adbf-ce6b-4bbc-9771-f682589aea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a function for plotting ROCX Curve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(fpr, trp):\n",
    "    \"\"\"\n",
    "    Plots a ROC curve given the false positive rate (fpr)\n",
    "    and true positive rate (tpr) of a model.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Plot ROC Curve\n",
    "    plt.plit(fpr,tpr,color=\"orange\", label=\"ROC\")\n",
    "\n",
    "    # Plot line with no predictive power (baseline) \n",
    "\n",
    "    plt.plot([0,1],[0,1], color=\"darkblue\",linestyle=\"--\", label =\"Guessing\")\n",
    "\n",
    "    # Customize the plot\n",
    "\n",
    "    plt.xlabel(\"False positive rate (fpr)\")\n",
    "    plt.ylabel(\"True positive rate (tpr)\")\n",
    "\n",
    "    plt.title(\"Receiver Operating Characteristics (ROC) Curve\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_roc_curve(fpr, tpr)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1692c02-64f0-4101-9957-3545ecd63ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    \"\"\"\n",
    "    Plots a ROC curve given the false positive rate (fpr)\n",
    "    and true positive rate (tpr) of a model.\n",
    "    \"\"\"\n",
    "    # Plot ROC Curve\n",
    "    plt.plot(fpr, tpr, color=\"orange\", label=\"ROC\")\n",
    "\n",
    "    # Plot line with no predictive power (baseline)\n",
    "    plt.plot([0, 1], [0, 1], color=\"darkblue\", linestyle=\"--\", label=\"Guessing\")\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "    plt.ylabel(\"True Positive Rate (TPR)\")\n",
    "    plt.title(\"Receiver Operating Characteristics (ROC) Curve\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming 'model' is your trained classifier and 'X_test' and 'y_test' are your test data\n",
    "# Get predicted probabilities for the positive class\n",
    "y_probs = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate FPR and TPR\n",
    "fpr, tpr, _ = roc_curve(y_test, y_probs)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plot_roc_curve(fpr, tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e6ecb7-08a7-4ecf-9156-33f6b76d8220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    \"\"\"\n",
    "    Plots a ROC curve given the false positive rate (fpr)\n",
    "    and true positive rate (tpr) of a model.\n",
    "    \"\"\"\n",
    "    # Plot ROC Curve\n",
    "    plt.plot(fpr, tpr, color=\"orange\", label=\"ROC\")\n",
    "\n",
    "    # Plot line with no predictive power (baseline)\n",
    "    plt.plot([0, 1], [0, 1], color=\"darkblue\", linestyle=\"--\", label=\"Guessing\")\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "    plt.ylabel(\"True Positive Rate (TPR)\")\n",
    "    plt.title(\"Receiver Operating Characteristics (ROC) Curve\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming 'model' is your trained classifier and 'X_test' and 'y_test' are your test data\n",
    "# Get predicted probabilities for the positive class\n",
    "y_probs = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate FPR and TPR\n",
    "fpr, tpr, _ = roc_curve(y_test, y_probs)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plot_roc_curve(fpr, tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5829e0df-bc54-439f-bfae-60f60286c2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    \"\"\"\n",
    "    Plots a ROC curve given the false positive rate (fpr)\n",
    "    and true positive rate (tpr) of a model.\n",
    "    \"\"\"\n",
    "    # Plot ROC Curve\n",
    "    plt.plot(fpr, tpr, color=\"orange\", label=\"ROC\")\n",
    "\n",
    "    # Plot line with no predictive power (baseline)\n",
    "    plt.plot([0, 1], [0, 1], color=\"darkblue\", linestyle=\"--\", label=\"Guessing\")\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "    plt.ylabel(\"True Positive Rate (TPR)\")\n",
    "    plt.title(\"Receiver Operating Characteristics (ROC) Curve\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming 'model' is your trained classifier and 'X_test' and 'y_test' are your test data\n",
    "# Get predicted probabilities for the positive class\n",
    "y_probs = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate FPR and TPR\n",
    "fpr, tpr, _ = roc_curve(y_test, y_probs)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plot_roc_curve(fpr, tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a3a187-0347-4ee7-91ce-506fe32dd525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def plot_roc_curve(y_true, y_proba):\n",
    "    \"\"\"\n",
    "    Plots the ROC curve given the true labels and predicted probabilities.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true: array-like of shape (n_samples,)\n",
    "        True binary labels.\n",
    "    - y_proba: array-like of shape (n_samples,)\n",
    "        Target scores, can either be probability estimates of the positive class, confidence values, or binary decisions.\n",
    "    \"\"\"\n",
    "    # Compute False Positive Rate (FPR) and True Positive Rate (TPR)\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
    "    # Compute Area Under the Curve (AUC)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Chance')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea3bfcf-25fe-4614-b2d9-16cd0dfaa313",
   "metadata": {},
   "source": [
    "## Create a function for plotting ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71748210-ccdb-4a3b-b5bc-c2c84e7d9663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a classifier\n",
    "clf = LogisticRegression(max_iter=10000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for the positive class\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Plot ROC curve\n",
    "plot_roc_curve(y_test, y_proba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4c544f-f124-483b-9fd5-c4b659635785",
   "metadata": {},
   "source": [
    "### Certainly! Let's break down the provided code step by step to understand its functionality:\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "```\n",
    "\n",
    "1. **Importing Necessary Libraries**:\n",
    "   - `load_breast_cancer` from `sklearn.datasets`: Loads the Breast Cancer Wisconsin dataset, which is commonly used for binary classification tasks.\n",
    "   - `train_test_split` from `sklearn.model_selection`: Splits the dataset into training and testing subsets.\n",
    "   - `LogisticRegression` from `sklearn.linear_model`: Implements logistic regression, a linear model for binary classification.\n",
    "\n",
    "```python\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "```\n",
    "\n",
    "2. **Loading the Dataset**:\n",
    "   - `load_breast_cancer()`: Loads the breast cancer dataset into the variable `data`.\n",
    "   - `X = data.data`: Assigns the features (input variables) to `X`.\n",
    "   - `y = data.target`: Assigns the target labels (output variable) to `y`.\n",
    "\n",
    "```python\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "```\n",
    "\n",
    "3. **Splitting the Data**:\n",
    "   - `train_test_split`: Divides the dataset into training and testing subsets.\n",
    "     - `test_size=0.3`: Specifies that 30% of the data will be used for testing, and 70% for training.\n",
    "     - `random_state=42`: Ensures reproducibility by setting a seed for random number generation.\n",
    "   - `X_train`, `X_test`: Contain the training and testing features, respectively.\n",
    "   - `y_train`, `y_test`: Contain the training and testing labels, respectively.\n",
    "\n",
    "```python\n",
    "# Train a classifier\n",
    "clf = LogisticRegression(max_iter=10000)\n",
    "clf.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "4. **Training the Logistic Regression Model**:\n",
    "   - `clf = LogisticRegression(max_iter=10000)`: Initializes the logistic regression classifier with a maximum of 10,000 iterations to ensure convergence.\n",
    "   - `clf.fit(X_train, y_train)`: Trains the classifier using the training data.\n",
    "\n",
    "```python\n",
    "# Predict probabilities for the positive class\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "```\n",
    "\n",
    "5. **Predicting Probabilities**:\n",
    "   - `clf.predict_proba(X_test)`: Predicts the probabilities of each class for the test data.\n",
    "   - `[:, 1]`: Extracts the probabilities of the positive class (class labeled as '1').\n",
    "   - `y_proba`: Contains the predicted probabilities for the positive class for each instance in the test set.\n",
    "\n",
    "```python\n",
    "# Plot ROC curve\n",
    "plot_roc_curve(y_test, y_proba)\n",
    "```\n",
    "\n",
    "6. **Plotting the ROC Curve**:\n",
    "   - `plot_roc_curve(y_test, y_proba)`: Calls a function (assumed to be defined elsewhere) that plots the Receiver Operating Characteristic (ROC) curve using the true labels (`y_test`) and the predicted probabilities (`y_proba`).\n",
    "\n",
    "**Understanding the ROC Curve**:\n",
    "\n",
    "- **ROC Curve**: A graphical representation that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. It plots:\n",
    "  - **True Positive Rate (TPR)**: Also known as sensitivity or recall; measures the proportion of actual positives correctly identified.\n",
    "  - **False Positive Rate (FPR)**: Measures the proportion of actual negatives incorrectly identified as positives.\n",
    "- **Purpose**: The ROC curve helps in evaluating the performance of a classification model by showing the trade-off between TPR and FPR across different threshold settings.\n",
    "- **Ideal Curve**: A model with perfect discrimination has an ROC curve that passes through the top-left corner (TPR=1, FPR=0).\n",
    "- **Area Under the Curve (AUC)**: A single scalar value summarizing the performance; a higher AUC indicates better model performance.\n",
    "\n",
    "By following these steps, the code trains a logistic regression model on the breast cancer dataset and evaluates its performance using the ROC curve, providing insights into the model's ability to distinguish between the two classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4756df99-d741-4b5d-9f24-82aa391bcd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test, y_probs_positive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed828f28-99b4-40ac-9fe6-95b5f7d6970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a classifier\n",
    "clf = LogisticRegression(max_iter=10000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for the test set\n",
    "y_probs = clf.predict_proba(X_test)\n",
    "\n",
    "# Extract probabilities for the positive class\n",
    "y_probs_positive = y_probs[:, 1]\n",
    "\n",
    "# Compute the ROC AUC score\n",
    "auc_score = roc_auc_score(y_test, y_probs_positive)\n",
    "print(f'ROC AUC Score: {auc_score:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90110822-d2da-47d8-8e06-32d5cc9ea5dd",
   "metadata": {},
   "source": [
    "### The **ROC score**, commonly referred to as the **Area Under the ROC Curve (AUC-ROC)**, is a metric used to evaluate the performance of a binary classification model. It quantifies the model's ability to distinguish between the positive and negative classes. The ROC curve itself is a graphical representation that illustrates the trade-off between the true positive rate (sensitivity) and the false positive rate (1 - specificity) across various threshold settings. \n",
    "\n",
    "The AUC-ROC score ranges from 0 to 1, where:\n",
    "\n",
    "- **1.0** indicates a perfect model that correctly classifies all positive and negative instances.\n",
    "- **0.5** suggests a model with no discriminative ability, equivalent to random guessing.\n",
    "- **Less than 0.5** implies a model performing worse than random chance, which may indicate a systematic error.\n",
    "\n",
    "A higher AUC-ROC score signifies better model performance in distinguishing between the classes. This metric is particularly useful when dealing with imbalanced datasets, as it provides a comprehensive measure of performance across all classification thresholds.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96331fe-7c94-4d7e-9cae-683290eed38e",
   "metadata": {},
   "source": [
    "## Plot Perfect ROC & AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d006afd-4602-4a79-99f4-221e8d98ddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_test)\n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1f0fdc-db01-44ec-a6fc-0acf82b05c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfect AUC Score\n",
    "\n",
    "roc_auc_score(y_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc181508-e29d-4103-9bcc-2a82f96873cc",
   "metadata": {},
   "source": [
    "### Reading Extension: ROC Curve + AUC\n",
    "When you first encounter them, ROC Curve and AUC (area under curve) metrics can be a little confusing. But not to worry, with a little practice, they'll start to make sense.\n",
    "\n",
    "In a nutshell, what you should remember is:\n",
    "\n",
    "ROC curves and AUC metrics are evaluation metrics for binary classification models (a model which predicts one thing or another, such as heart disease or not).\n",
    "\n",
    "The ROC curve compares the true positive rate (tpr) versus the false positive rate (fpr) at different classification thresholds.\n",
    "\n",
    "The AUC metric tells you how well your model is at choosing between classes (for example, how well it is at deciding whether someone has heart disease or not). A perfect model will get an AUC score of 1.\n",
    "\n",
    "For more information on these metrics, bookmark the following resources and refer to them when you need:\n",
    "\n",
    "ROC and AUC, Clearly Explained! by StatQuest\n",
    "\n",
    "ROC documentation in Scikit-Learn (contains code examples)\n",
    "\n",
    "How the ROC curve and AUC are calculated by Google's Machine Learning team"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fa3e0c-d0b5-4051-89f1-4b2e30b0c758",
   "metadata": {},
   "source": [
    "## Confusion Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e58131b-dcb4-46dc-ae0b-c332e3c961ef",
   "metadata": {},
   "source": [
    "### A **confusion matrix** is a table used to evaluate the performance of a classification model by comparing its predicted outputs to the actual outcomes. It provides a comprehensive breakdown of correct and incorrect predictions, offering deeper insight than a simple accuracy metric. \n",
    "\n",
    "In a binary classification scenario, the confusion matrix is structured as follows:\n",
    "\n",
    "| Actual\\Predicted | Positive (1) | Negative (0) |\n",
    "|------------------|--------------|--------------|\n",
    "| Positive (1)     | True Positive (TP)  | False Negative (FN) |\n",
    "| Negative (0)     | False Positive (FP) | True Negative (TN)  |\n",
    "\n",
    "**Components:**\n",
    "\n",
    "- **True Positive (TP):** Instances where the model correctly predicts the positive class.\n",
    "- **True Negative (TN):** Instances where the model correctly predicts the negative class.\n",
    "- **False Positive (FP):** Instances where the model incorrectly predicts the positive class (Type I error).\n",
    "- **False Negative (FN):** Instances where the model incorrectly predicts the negative class (Type II error).\n",
    "\n",
    "These components are essential for calculating various performance metrics:\n",
    "\n",
    "- **Accuracy:** Measures the proportion of correct predictions (both TP and TN) out of all predictions.\n",
    "\n",
    "  \\[\n",
    "  \\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "  \\]\n",
    "\n",
    "- **Precision:** Indicates the proportion of true positive predictions among all positive predictions made by the model.\n",
    "\n",
    "  \\[\n",
    "  \\text{Precision} = \\frac{TP}{TP + FP}\n",
    "  \\]\n",
    "\n",
    "- **Recall (Sensitivity or True Positive Rate):** Reflects the proportion of actual positives correctly identified by the model.\n",
    "\n",
    "  \\[\n",
    "  \\text{Recall} = \\frac{TP}{TP + FN}\n",
    "  \\]\n",
    "\n",
    "- **Specificity (True Negative Rate):** Represents the proportion of actual negatives correctly identified.\n",
    "\n",
    "  \\[\n",
    "  \\text{Specificity} = \\frac{TN}{TN + FP}\n",
    "  \\]\n",
    "\n",
    "- **F1 Score:** The harmonic mean of precision and recall, providing a balance between the two.\n",
    "\n",
    "  \\[\n",
    "  \\text{F1 Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "  \\]\n",
    "\n",
    "Understanding the confusion matrix and its derived metrics is crucial for assessing model performance, especially when dealing with imbalanced datasets. It allows practitioners to identify specific areas where the model may be underperforming, such as high false positive or false negative rates, and make informed decisions to address these issues.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dd9310-8f51-4a3d-87bb-3559dee07bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Metrics\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Generate predictions using the test data\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_preds)\n",
    "\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8274a8-2e14-4a86-8a16-80237d709fef",
   "metadata": {},
   "source": [
    "### The provided code snippet is used to evaluate the performance of a classification model by computing its **confusion matrix**. Let's break it down step by step in simple terms:\n",
    "\n",
    "1. **Importing the Function**:\n",
    "   ```python\n",
    "   from sklearn.metrics import confusion_matrix\n",
    "   ```\n",
    "   This line imports the `confusion_matrix` function from the `sklearn.metrics` module. This function helps in comparing the actual outcomes with the model's predictions.\n",
    "\n",
    "2. **Making Predictions**:\n",
    "   ```python\n",
    "   y_preds = clf.predict(X_test)\n",
    "   ```\n",
    "   Here, `clf` represents your trained classification model. The `predict` method is used to make predictions on the test data `X_test`, resulting in `y_preds`, which are the predicted labels.\n",
    "\n",
    "3. **Computing the Confusion Matrix**:\n",
    "   ```python\n",
    "   cm = confusion_matrix(y_test, y_preds)\n",
    "   ```\n",
    "   This line calculates the confusion matrix by comparing the true labels (`y_test`) with the predicted labels (`y_preds`). The resulting `cm` is a table that summarizes the model's performance.\n",
    "\n",
    "4. **Displaying the Confusion Matrix**:\n",
    "   ```python\n",
    "   print(cm)\n",
    "   ```\n",
    "   Finally, this line prints the confusion matrix to the console.\n",
    "\n",
    "**Understanding the Confusion Matrix**:\n",
    "\n",
    "A confusion matrix is a table that helps you understand how well your classification model is performing. For a binary classification (two classes), it looks like this:\n",
    "\n",
    "| Actual \\ Predicted | Predicted Positive | Predicted Negative |\n",
    "|--------------------|--------------------|--------------------|\n",
    "| **Actual Positive** | True Positive (TP) | False Negative (FN)|\n",
    "| **Actual Negative** | False Positive (FP)| True Negative (TN) |\n",
    "\n",
    "- **True Positive (TP)**: The model correctly predicted the positive class.\n",
    "- **True Negative (TN)**: The model correctly predicted the negative class.\n",
    "- **False Positive (FP)**: The model incorrectly predicted as positive when it's actually negative.\n",
    "- **False Negative (FN)**: The model incorrectly predicted as negative when it's actually positive.\n",
    "\n",
    "By analyzing these values, you can determine how many mistakes your model is making and what types of errors are most common. This information is crucial for improving your model's accuracy.\n",
    "\n",
    "For more detailed information, you can refer to the [Scikit-learn documentation on confusion matrices](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2341795e-b086-4c06-8bca-82dfb36604cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Confusion Metrix With pd.crosstab()\n",
    "\n",
    "pd.crosstab(y_test,\n",
    "            y_preds, \n",
    "            rownames=[\"Actual Labels\"],\n",
    "            colnames=[\"Predicted Labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4c55cf-8410-4612-823e-b6fdb38e73e3",
   "metadata": {},
   "source": [
    "### The provided code snippet utilizes the `pandas` library's `crosstab` function to create a confusion matrix, which helps in evaluating the performance of a classification model. Here's a step-by-step explanation:\n",
    "\n",
    "1. **`pd.crosstab` Function**:\n",
    "   - `pandas.crosstab` computes a cross-tabulation of two or more factors. In this context, it's used to compare the actual labels (`y_test`) with the predicted labels (`y_preds`).\n",
    "   - The function signature is:\n",
    "     ```python\n",
    "     pd.crosstab(index, columns, rownames=None, colnames=None)\n",
    "     ```\n",
    "     - `index`: Values to group by in the rows (here, `y_test`).\n",
    "     - `columns`: Values to group by in the columns (here, `y_preds`).\n",
    "     - `rownames`: Names for the row indices; here, it's set to `[\"Actual Labels\"]`.\n",
    "     - `colnames`: Names for the column indices; here, it's set to `[\"Predicted Labels\"]`.\n",
    "\n",
    "2. **Parameters**:\n",
    "   - `y_test`: The actual labels from the test dataset.\n",
    "   - `y_preds`: The labels predicted by the classification model.\n",
    "   - `rownames=[\"Actual Labels\"]`: Sets the name for the rows in the resulting table to \"Actual Labels\".\n",
    "   - `colnames=[\"Predicted Labels\"]`: Sets the name for the columns in the resulting table to \"Predicted Labels\".\n",
    "\n",
    "3. **Output**:\n",
    "   - The function returns a DataFrame that displays the frequency of each combination of actual and predicted labels. This table is the confusion matrix, which helps in understanding how well the model's predictions match the actual labels.\n",
    "\n",
    "**Example**:\n",
    "\n",
    "Suppose `y_test` and `y_preds` are as follows:\n",
    "\n",
    "```python\n",
    "y_test = [0, 1, 0, 1, 0, 1, 0, 1]\n",
    "y_preds = [0, 0, 0, 1, 0, 1, 1, 1]\n",
    "```\n",
    "\n",
    "Using `pd.crosstab`:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "conf_matrix = pd.crosstab(y_test, y_preds, rownames=[\"Actual Labels\"], colnames=[\"Predicted Labels\"])\n",
    "print(conf_matrix)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "Predicted Labels  0  1\n",
    "Actual Labels         \n",
    "0                 2  1\n",
    "1                 1  2\n",
    "```\n",
    "\n",
    "**Interpretation**:\n",
    "\n",
    "- **True Positives (TP)**: 2 instances where the actual label is 1 and the model predicted 1.\n",
    "- **True Negatives (TN)**: 2 instances where the actual label is 0 and the model predicted 0.\n",
    "- **False Positives (FP)**: 1 instance where the actual label is 0 but the model predicted 1.\n",
    "- **False Negatives (FN)**: 1 instance where the actual label is 1 but the model predicted 0.\n",
    "\n",
    "This confusion matrix provides a clear summary of the model's performance, indicating how many predictions were correct and where the model made errors.\n",
    "\n",
    "For more details on the `pandas.crosstab` function, you can refer to the official documentation:\n",
    "\n",
    "[pandas.crosstab — pandas documentation](https://pandas.pydata.org/docs/reference/api/pandas.crosstab.html) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb91133-7d8e-4eb0-aa95-682b7d632591",
   "metadata": {},
   "source": [
    "## Make Confusion Metrix More Visual With Seaborn's Heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db97730-83d2-429b-809a-1946db70af0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming y_test contains the true labels and y_preds contains the predicted labels\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_preds)\n",
    "\n",
    "# Create a D\n",
    "ataFrame for better visualization\n",
    "cm_df = pd.DataFrame(cm, index=['Actual Negative', 'Actual Positive'],\n",
    "                     columns=['Predicted Negative', 'Predicted Positive'])\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual Labels')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0c3cfd-4591-4b2e-a6de-f2c6b692e66e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6886294f-715d-4c19-b17d-ae1a34284ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Set the font scale\n",
    "sns.set(font_scale = 1.5)\n",
    "\n",
    "# Create a confusion Metrix\n",
    "conf_mat = confusion_matrix(y_test, y_preds)\n",
    "\n",
    "# Plot it using sesborn\n",
    "sns.heatmap(conf_mat);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91225ca1-713d-4a73-b512-be59ccdda39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, y_preds)\n",
    "\n",
    "# Set the font scale for better readability\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "# Create a heatmap to visualize the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['Predicted Negative', 'Predicted Positive'],\n",
    "            yticklabels=['Actual Negative', 'Actual Positive'])\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('Actual Labels')\n",
    "plt.title('Confusion Matrix Heatmap')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b59198-2aea-4a34-ad09-fb94b24f4b20",
   "metadata": {},
   "source": [
    "## Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45b036b-4126-4c6c-975d-3c3fa6c34962",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming y_test contains the true labels and y_preds contains the predicted labels\n",
    "print(classification_report(y_test, y_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b4f3b1-e3c3-454d-9328-96134d6d2b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the model\n",
    "clf = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels for the test set\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460ca1b4-1e00-48de-9b32-72ad0be17496",
   "metadata": {},
   "source": [
    "### This Python code demonstrates how to load the breast cancer dataset, train a logistic regression model, and evaluate its performance using a classification report. Here's a step-by-step explanation:\n",
    "\n",
    "1. **Import Necessary Libraries**:\n",
    "   ```python\n",
    "   from sklearn.datasets import load_breast_cancer\n",
    "   from sklearn.model_selection import train_test_split\n",
    "   from sklearn.linear_model import LogisticRegression\n",
    "   from sklearn.metrics import classification_report\n",
    "   ```\n",
    "   - `load_breast_cancer`: Loads the breast cancer dataset.\n",
    "   - `train_test_split`: Splits the data into training and testing sets.\n",
    "   - `LogisticRegression`: Implements the logistic regression model.\n",
    "   - `classification_report`: Generates a report of classification metrics.\n",
    "\n",
    "2. **Load the Dataset**:\n",
    "   ```python\n",
    "   data = load_breast_cancer()\n",
    "   X = data.data\n",
    "   y = data.target\n",
    "   ```\n",
    "   - `data`: Loads the breast cancer dataset, which includes features and target labels.\n",
    "   - `X`: Contains the feature matrix (569 samples, 30 features).\n",
    "   - `y`: Contains the target vector (569 labels: 0 for malignant, 1 for benign).\n",
    "\n",
    "3. **Split the Data**:\n",
    "   ```python\n",
    "   X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "   ```\n",
    "   - Splits the data into training and testing sets.\n",
    "   - `test_size=0.3`: 30% of the data is used for testing.\n",
    "   - `random_state=42`: Ensures reproducibility of the split.\n",
    "\n",
    "4. **Initialize the Model**:\n",
    "   ```python\n",
    "   clf = LogisticRegression(max_iter=10000)\n",
    "   ```\n",
    "   - `clf`: Initializes a logistic regression model with a maximum of 10,000 iterations to ensure convergence.\n",
    "\n",
    "5. **Train the Model**:\n",
    "   ```python\n",
    "   clf.fit(X_train, y_train)\n",
    "   ```\n",
    "   - Trains the logistic regression model using the training data.\n",
    "\n",
    "6. **Make Predictions**:\n",
    "   ```python\n",
    "   y_preds = clf.predict(X_test)\n",
    "   ```\n",
    "   - `y_preds`: Predicts the labels for the test set.\n",
    "\n",
    "7. **Evaluate the Model**:\n",
    "   ```python\n",
    "   print(classification_report(y_test, y_preds))\n",
    "   ```\n",
    "   - Generates and prints a classification report comparing the true labels (`y_test`) with the predicted labels (`y_preds`).\n",
    "   - The report includes metrics such as precision, recall, F1-score, and support for each class.\n",
    "\n",
    "**Output Example**:\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       0       0.97      0.97      0.97       171\n",
    "       1       0.96      0.96      0.96       198\n",
    "\n",
    "    accuracy                           0.96       369\n",
    "   macro avg       0.96      0.96      0.96       369\n",
    "weighted avg       0.96      0.96      0.96       369\n",
    "```\n",
    "- **Precision**: The ratio of correctly predicted positive observations to the total predicted positives.\n",
    "- **Recall**: The ratio of correctly predicted positive observations to all observations in the actual class.\n",
    "- **F1-Score**: The weighted average of Precision and Recall.\n",
    "- **Support**: The number of actual occurrences of each class in the dataset.\n",
    "\n",
    "This classification report provides a comprehensive overview of the model's performance on the test set.\n",
    "\n",
    "For a visual explanation of the classification report, you might find the following video helpful:\n",
    "\n",
    "[Understanding Classification Report in Machine Learning](https://www.youtube.com/watch?v=98LX2iRWXsY) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcb265f-16b7-446d-9dc5-88c55118b643",
   "metadata": {},
   "source": [
    "## Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfc5363-3d3b-4898-834b-322f6bb5e0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_preds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d5db28-b517-4c64-baf5-c84d7c55ba35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where precision and recallbecome valuable\n",
    "\n",
    "diesease_true = np.zeros(10000)\n",
    "diesease_true[0] = 1 # Only One Positive Case\n",
    "\n",
    "disease_preds = np.zeros(10000) \" Model predicts every case as 0\n",
    "\n",
    "pd.DataFrame(classification_report(disease_true,\n",
    "                                   disease_preds,\n",
    "                                   output_dict=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc1c773-c407-4498-8ffd-a1cc4d6c5f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where precision and recall become valuable\n",
    "\n",
    "disease_true = np.zeros(10000)\n",
    "disease_true[0] = 1  # Only one positive case\n",
    "\n",
    "disease_preds = np.zeros(10000)  # Model predicts every case as 0\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Generate the classification report\n",
    "report = pd.DataFrame(classification_report(disease_true,\n",
    "                                            disease_preds,\n",
    "                                            output_dict=True))\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aa6f47-1c77-4893-8af9-eac5714df9c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ad8448-2c59-4a55-9d49-c02a29d12cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Regression Model Evaluatiion Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444211a3-df48-457e-af30-4d8ee4320f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegresor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "x = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "x_tarin, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
    "\n",
    "model = RandomForestRegresor(n_estimators=100)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "model.fit(x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52fc7ad-678c-4a44-ba41-21dec3551c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "x = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Remove the second fit, as it's not necessary and can cause issues\n",
    "# model.fit(x_test, y_test)\n",
    "\n",
    "# Instead, use the trained model to make predictions on the test set\n",
    "y_pred = model.predict(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e27564-cc6e-4378-9b00-2c3469637f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Assuming housing_df is already defined\n",
    "x = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Use the trained model to make predictions on the test set\n",
    "y_pred = model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daee1502-54cd-4147-88f9-dbed1642aa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Assuming housing_df is loaded correctly\n",
    "print(housing_df.columns)  # Inspect the columns to confirm the target column name\n",
    "\n",
    "# Update \"target\" to the actual column name\n",
    "target_column = \"Target\"  # Replace with the correct column name\n",
    "x = housing_df.drop(target_column, axis=1)\n",
    "y = housing_df[target_column]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893233e0-9f2d-4e7f-b47d-ffeccb2fc52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(housing_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65bd237-1954-48e1-a484-3236caa8675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63472bbf-6fbe-4d98-9e2c-e50a5c606484",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e910e94-1fc7-41ce-8862-457658d4d4d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_test\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c973fbd-3d65-4839-aa9d-fd8468183a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Fill an array with y_test mean\n",
    "\n",
    "y_test_mean = np.full(len(y_test), y_test.mean())\n",
    "\n",
    "y_test_mean[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4646ac5e-6c2d-4908-b1eb-2bb17ae20f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d84d7df-024f-4421-839a-885115cad7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_true = y_test,\n",
    "         y_pred = y_test_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf6ba3a-b540-4f05-8df1-258ce1f20536",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_true = y_test,\n",
    "         y_pred = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f845b963-3617-4205-87b6-8c8a8e81bb1b",
   "metadata": {},
   "source": [
    "## Regression Model Evolution Metrics: Using R^2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9800d4-b728-4456-b027-ce68fb2997a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Fill an array with y_test mean\n",
    "\n",
    "y_test_mean = np.full(len(y_test), y_test.mean())\n",
    "\n",
    "y_test_mean[:10]\n",
    "\n",
    "r2_score(y_true = y_test,\n",
    "         y_pred = y_test_mean)\n",
    "\n",
    "r2_score(y_true = y_test,\n",
    "         y_pred = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e81e421-3601-4e39-9d4e-6daddcf4ef98",
   "metadata": {},
   "source": [
    "### The `r2_score` function from `sklearn.metrics` is used to evaluate the performance of a regression model by calculating the **R-squared (R²)** value. This metric indicates how well the predicted values match the true values in the data. Here's a breakdown of what each part does and its significance in the code:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Filling an Array with the Mean of `y_test`**\n",
    "\n",
    "```python\n",
    "y_test_mean = np.full(len(y_test), y_test.mean())\n",
    "```\n",
    "\n",
    "- **Purpose**: Creates an array `y_test_mean` where all values are the mean of the `y_test` array.\n",
    "- **Why?**: This simulates a baseline prediction model where the prediction for every input is the mean of the true values. It is often used as a naive benchmark.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Calculating `r2_score` Using `y_test_mean`\n",
    "\n",
    "```python\n",
    "r2_score(y_true = y_test, y_pred = y_test_mean)\n",
    "```\n",
    "\n",
    "- **Inputs**:\n",
    "  - `y_true`: The actual values (`y_test`).\n",
    "  - `y_pred`: The predicted values (here, the mean values of `y_test`).\n",
    "- **Output**: The R² value for this baseline model.\n",
    "  \n",
    "**Interpretation**:\n",
    "- The R² value here shows how well the mean value predicts the actual values. Typically, this is used as a lower bound for evaluating other models. A good model should have a higher R² value than this baseline.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Calculating `r2_score` Using `y_test` as Both `y_true` and `y_pred`\n",
    "\n",
    "```python\n",
    "r2_score(y_true = y_test, y_pred = y_test)\n",
    "```\n",
    "\n",
    "- **Inputs**:\n",
    "  - `y_true`: The actual values (`y_test`).\n",
    "  - `y_pred`: The predicted values (also `y_test`).\n",
    "- **Output**: The R² value for a \"perfect model.\"\n",
    "  \n",
    "**Interpretation**:\n",
    "- When `y_pred` equals `y_true`, the predictions are perfect, and the R² value will always be **1.0**. This is the theoretical upper bound for R².\n",
    "\n",
    "---\n",
    "\n",
    "### **Use of R² (R-squared)**\n",
    "\n",
    "- **Definition**: R² measures the proportion of the variance in the dependent variable (`y_test`) that is predictable from the independent variables.\n",
    "- **Range**: \n",
    "  - \\( R^2 = 1.0 \\): Perfect predictions.\n",
    "  - \\( R^2 = 0.0 \\): Predictions are as good as always predicting the mean.\n",
    "  - \\( R^2 < 0.0 \\): Predictions are worse than just predicting the mean.\n",
    "\n",
    "**Applications**:\n",
    "- Compare different models or algorithms to evaluate how well they perform.\n",
    "- Assess the quality of a model compared to a naive baseline (mean-based predictions).\n",
    "\n",
    "---\n",
    "\n",
    "In your code:\n",
    "- The first `r2_score` evaluates the baseline (mean predictions).\n",
    "- The second `r2_score` shows the best possible score (perfect predictions).\n",
    "\n",
    "If you're building a regression model, its R² value should ideally fall between these two extremes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a210e5-52af-4111-9861-a58b5e572c1d",
   "metadata": {},
   "source": [
    "## R² (R-squared) as a regression model evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bbe7a5-9e1b-4dcd-8e57-8b17c414c279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# Generate a synthetic regression dataset\n",
    "X, y = make_regression(n_samples=100, n_features=1, noise=10, random_state=42)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a simple Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Baseline R²: Use the mean of y_test as predictions\n",
    "y_test_mean = np.full(len(y_test), y_test.mean())\n",
    "baseline_r2 = r2_score(y_true=y_test, y_pred=y_test_mean)\n",
    "\n",
    "# Model R²: Use model predictions\n",
    "model_r2 = r2_score(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "# Perfect R²: Compare y_test with itself\n",
    "perfect_r2 = r2_score(y_true=y_test, y_pred=y_test)\n",
    "\n",
    "# Print the results\n",
    "print(\"Baseline R² (mean predictions):\", baseline_r2)\n",
    "print(\"Model R² (Linear Regression):\", model_r2)\n",
    "print(\"Perfect R² (ideal case):\", perfect_r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b25af2a-0c88-4d70-83c5-b077f3e176e4",
   "metadata": {},
   "source": [
    "## Evaluating a regression model using Mean Absolute Error (MAE) as the evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43978a68-74cf-4777-8f1e-97bb731ba13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# Generate a synthetic regression dataset\n",
    "X, y = make_regression(n_samples=100, n_features=1, noise=10, random_state=42)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a simple Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Baseline MAE: Mean predictions as baseline\n",
    "y_test_mean = np.full(len(y_test), y_test.mean())\n",
    "baseline_mae = mean_absolute_error(y_test, y_test_mean)\n",
    "\n",
    "# Model MAE: Using model predictions\n",
    "model_mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Baseline MAE (mean predictions):\", baseline_mae)\n",
    "print(\"Model MAE (Linear Regression):\", model_mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8e2495-2972-45d2-a6ad-17fbc777c343",
   "metadata": {},
   "source": [
    "### Here's a detailed line-by-line explanation of the provided code:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Import Necessary Libraries**\n",
    "```python\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "```\n",
    "- **Purpose**: Import the libraries required for data generation, model training, and evaluation.\n",
    "  - `numpy`: For numerical operations.\n",
    "  - `mean_absolute_error`: To compute the Mean Absolute Error (MAE), a metric that calculates the average absolute difference between actual and predicted values.\n",
    "  - `train_test_split`: To split the dataset into training and testing subsets.\n",
    "  - `LinearRegression`: To train a simple regression model.\n",
    "  - `make_regression`: To generate synthetic regression data.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Generate Synthetic Regression Data**\n",
    "```python\n",
    "X, y = make_regression(n_samples=100, n_features=1, noise=10, random_state=42)\n",
    "```\n",
    "- **Purpose**: Create a regression dataset with 100 samples, 1 feature, and some added noise.\n",
    "  - `n_samples=100`: Number of data points (rows).\n",
    "  - `n_features=1`: Number of features (columns).\n",
    "  - `noise=10`: Adds randomness to the target variable `y` to make the dataset more realistic.\n",
    "  - `random_state=42`: Ensures reproducibility of the generated data.\n",
    "- **Output**: \n",
    "  - `X`: A 2D array with 100 rows and 1 column (input feature).\n",
    "  - `y`: A 1D array with 100 target values corresponding to `X`.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Split the Data**\n",
    "```python\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "```\n",
    "- **Purpose**: Divide the dataset into training and testing subsets.\n",
    "  - `test_size=0.2`: 20% of the data is reserved for testing.\n",
    "  - `random_state=42`: Ensures consistent splits across runs.\n",
    "- **Output**:\n",
    "  - `X_train`, `y_train`: Training inputs and targets (80% of the data).\n",
    "  - `X_test`, `y_test`: Testing inputs and targets (20% of the data).\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Train a Linear Regression Model**\n",
    "```python\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "- **Purpose**:\n",
    "  - `LinearRegression()`: Initializes a linear regression model.\n",
    "  - `fit(X_train, y_train)`: Trains the model using the training data.\n",
    "- **Outcome**: The model learns the best-fit line for predicting `y` given `X`.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Make Predictions**\n",
    "```python\n",
    "y_pred = model.predict(X_test)\n",
    "```\n",
    "- **Purpose**: Predict the target values (`y_pred`) for the test inputs (`X_test`) using the trained model.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Baseline MAE**\n",
    "```python\n",
    "y_test_mean = np.full(len(y_test), y_test.mean())\n",
    "baseline_mae = mean_absolute_error(y_test, y_test_mean)\n",
    "```\n",
    "- **Purpose**: Calculate the **Mean Absolute Error (MAE)** for a naive baseline model.\n",
    "  - `y_test.mean()`: Computes the mean of the test target values (`y_test`).\n",
    "  - `np.full(len(y_test), y_test.mean())`: Creates an array (`y_test_mean`) of the same length as `y_test`, filled with the mean value.\n",
    "  - `mean_absolute_error(y_test, y_test_mean)`: Calculates the average absolute difference between the actual values (`y_test`) and the mean values (`y_test_mean`).\n",
    "- **Output**: The baseline MAE, representing the error of a model that always predicts the mean of `y_test`.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Model MAE**\n",
    "```python\n",
    "model_mae = mean_absolute_error(y_test, y_pred)\n",
    "```\n",
    "- **Purpose**: Calculate the **Mean Absolute Error (MAE)** for the trained linear regression model.\n",
    "  - `mean_absolute_error(y_test, y_pred)`: Computes the average absolute difference between the actual values (`y_test`) and the predicted values (`y_pred`).\n",
    "- **Output**: The MAE of the linear regression model.\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Print Results**\n",
    "```python\n",
    "print(\"Baseline MAE (mean predictions):\", baseline_mae)\n",
    "print(\"Model MAE (Linear Regression):\", model_mae)\n",
    "```\n",
    "- **Purpose**: Display the evaluation metrics.\n",
    "  - Baseline MAE indicates the performance of a naive model that predicts the mean of `y_test`.\n",
    "  - Model MAE reflects the performance of the trained regression model.\n",
    "\n",
    "---\n",
    "\n",
    "### **Expected Output**\n",
    "For a typical dataset:\n",
    "```\n",
    "Baseline MAE (mean predictions): 8.42\n",
    "Model MAE (Linear Regression): 3.12\n",
    "```\n",
    "\n",
    "- **Baseline MAE (`8.42`)**: Error of the naive model predicting the mean of `y_test`.\n",
    "- **Model MAE (`3.12`)**: Error of the trained regression model, which is expected to perform better than the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5513dc30-d17a-4595-beea-e9361b65cab3",
   "metadata": {},
   "source": [
    "## MAE is the average of the absolute differences between predictions andactual values.\n",
    "\n",
    "It gives us an idea of how wrong our models predictions are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7135f6d9-7f4a-48e3-91e6-ace08611d3f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2841456228.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[13], line 7\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(\"Mean Absolute Error (MAE):\", mae)|\u001b[0m\n\u001b[1;37m                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# MAE\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_preds = model.predict(X_test)  # Corrected variable name to match X_test\n",
    "mae = mean_absolute_error(y_test, y_preds)  # Calculate MAE\n",
    "print(\"Mean Absolute Error (MAE):\", mae)|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e6a7be-f779-407c-aa74-6ab1257011ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a37aa5-27a7-40f3-a85f-152a1a12544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e535025-c5d0-4e44-bc1f-2accfdbcedf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\"actual values\": y_test,\n",
    "                       \"predicted values\": y_preds})\n",
    "df[\"differences\"] = df[\"predicted values\"] - df[\"actual values\"]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a67cdcc-ebe3-43a7-a411-e6decedc592b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_test\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223713fd-5bee-4e4d-9741-b797acc8bd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afb4283-04f2-4772-a84d-ce1082296f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"differences\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e840312-1824-41a7-9863-73a4509adeb0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# MAE using formulas and differences\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m np\u001b[38;5;241m.\u001b[39mabs(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferences\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# MAE using formulas and differences\n",
    "\n",
    "np.abs(df[\"differences\"]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548b4603-2646-4b7f-88f7-0f94ecfe5472",
   "metadata": {},
   "source": [
    "## Mean Squared Error (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dba657-01ee-42ac-a183-40664883adb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming `model` is already trained and `x_test` and `y_test` are defined\n",
    "y_preds = model.predict(x_test)  # Predict the target values\n",
    "mse = mean_squared_error(y_test, y_preds)  # Calculate Mean Squared Error\n",
    "print(f\"Mean Squared Error: {mse}\")  # Print the MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6fe8ffd6-87ce-42a9-9b2f-9d7edcc1c070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 90000.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor  # Example model\n",
    "import pandas as pd\n",
    "\n",
    "# Example: Sample data\n",
    "data = pd.DataFrame({\n",
    "    'Brand': ['Nissan', 'Toyota', 'Ford', 'BMW', 'Nissan'],\n",
    "    'Year': [2010, 2012, 2015, 2018, 2020],\n",
    "    'Price': [5000, 7000, 10000, 20000, 15000]\n",
    "})\n",
    "\n",
    "# Encoding categorical data (e.g., 'Brand') using LabelEncoder\n",
    "le = LabelEncoder()\n",
    "data['Brand'] = le.fit_transform(data['Brand'])\n",
    "\n",
    "# Separating features (X) and target (y)\n",
    "X = data.drop('Price', axis=1)  # Features: 'Brand' and 'Year'\n",
    "y = data['Price']  # Target: 'Price'\n",
    "\n",
    "# Splitting data into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initializing and training a sample model (Random Forest Regressor)\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_preds = model.predict(x_test)\n",
    "\n",
    "# Calculating Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_preds)\n",
    "print(f\"Mean Squared Error: {mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4359300d-4350-4d50-aa5c-79d583fa7912",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msquared_differces\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msquare(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferences\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df[\"squared_differces\"] = np.square(df[\"differences\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6a38ec-6f77-4522-a022-b678887bd50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE by hand\n",
    "\n",
    "squared = np.square(df[\"differences\"])\n",
    "squared.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b8feec-fcdd-47e7-aa96-7e2173bf3d8b",
   "metadata": {},
   "source": [
    "## Mean Squared Error (MSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a44391-88f0-41df-a252-f5696a815dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Function to calculate MSE\n",
    "def calculate_mse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the Mean Squared Error (MSE) manually.\n",
    "\n",
    "    Parameters:\n",
    "        y_true (list or np.array): Actual target values.\n",
    "        y_pred (list or np.array): Predicted values from the model.\n",
    "\n",
    "    Returns:\n",
    "        float: Mean Squared Error value.\n",
    "    \"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    mse = np.mean((y_true - y_pred) ** 2)\n",
    "    return mse\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Actual values (y_true) and predicted values (y_pred)\n",
    "    y_true = [3.0, -0.5, 2.0, 7.0]\n",
    "    y_pred = [2.5, 0.0, 2.0, 8.0]\n",
    "\n",
    "    # Manual MSE calculation\n",
    "    mse_manual = calculate_mse(y_true, y_pred)\n",
    "    print(f\"Manual MSE: {mse_manual}\")\n",
    "\n",
    "    # Using sklearn for MSE calculation\n",
    "    mse_sklearn = mean_squared_error(y_true, y_pred)\n",
    "    print(f\"Sklearn MSE: {mse_sklearn}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a768a8-020f-4b10-bd4a-fd2a188f7a3b",
   "metadata": {},
   "source": [
    "## Using Scoring parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4093a124-d65d-4161-a48f-01df1298d8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble  import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "x = heart_disease.drop(\"target\", axis = 1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f62070-8227-49b0-b0e4-0bbddb1ee227",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Cross-Validation Accuracy\n",
    "cv_acc = cross_val_score(clf, x, y, cv=5, scoring=None)\n",
    "cv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec83061d-b81a-499d-b549-514035191ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Validated Accuracy\n",
    "print(f\"The Cross-Validated Accuracy Is: {np.mean(cv_acc) * 100: .2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1385d3d-c21b-4cb0-bec6-d5e941fe285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "cv_acc = cross_val_score(clf, x, y, cv=5, scoring=\"accuracy\")\n",
    "cv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13e7139-af4f-449e-807f-53dc6f7f4ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Validated Accuracy\n",
    "print(f\"The Cross-Validated Accuracy Is: {np.mean(cv_acc) * 100: .2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c918d12-7d54-4ad5-b961-99054b9011a7",
   "metadata": {},
   "source": [
    "## Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bfbc16ce-a070-442a-be09-0d5519f77112",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cross_val_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m cv_precision \u001b[38;5;241m=\u001b[39m cross_val_score(clf, x, y, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m cv_precision\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cross_val_score' is not defined"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "cv_precision = cross_val_score(clf, x, y, cv=5, scoring=\"precision\")\n",
    "cv_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f51387e-0ba9-404b-b94d-df7705db58d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Validated Precision\n",
    "print(f\"The Cross-Validated Precision Is: {np.mean(cv_precision)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a28f709-cac5-4cc1-8948-9e1294859a84",
   "metadata": {},
   "source": [
    "## Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4a24e68-46c1-498d-b4d1-1b7c70a24f77",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cross_val_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m cv_recall \u001b[38;5;241m=\u001b[39m cross_val_score(clf, x, y, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m cv_recall\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cross_val_score' is not defined"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "cv_recall = cross_val_score(clf, x, y, cv=5, scoring=\"recall\")\n",
    "cv_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f7925a-0c55-48d2-858b-5f0ab297dcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Validated Recall\n",
    "print(f\"The Cross-Validated Recall Is: {np.mean(cv_recall)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27823cb6-f896-4997-8258-d6a4a39811af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "x = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e009ce-45bc-4d62-931d-8a150d19541f",
   "metadata": {},
   "source": [
    "## Another way to evoluate scikit-learn ML Models/Estimators as Scikit-Learn functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "09ff7b36-e444-4790-ad1d-bcfdbd12ecf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Metrics on the Test Set\n",
      "Accuracy: 83.61%\n",
      "Precisdion : 0.84375\n",
      "Recall: 0.8360655737704918\n",
      "F1: 0.8360655737704918\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Assuming heart_disease is a DataFrame that is already defined\n",
    "# Create X and y\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the model\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model using evaluation function\n",
    "print(\"Classifier Metrics on the Test Set\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_preds) * 100:.2f}%\")\n",
    "print(f\"Precisdion : {precision_score(y_test, y_preds)}\")\n",
    "print(f\"Recall: {accuracy_score(y_test, y_preds)}\")\n",
    "print(f\"F1: {accuracy_score(y_test, y_preds)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "003f8055-ed0c-47c0-94a3-52f23451bd1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'housing_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Assuming housing_df is a DataFrame that is already defined\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Create X and y\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m X \u001b[38;5;241m=\u001b[39m housing_df\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     11\u001b[0m y \u001b[38;5;241m=\u001b[39m housing_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Split the data\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'housing_df' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Assuming housing_df is a DataFrame that is already defined\n",
    "# Create X and y\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the model\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_preds = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using evaluation functions\n",
    "print(\"Regression Metrics on the Test Set\")\n",
    "print(f\"R2 Score: {r2_score(y_test, y_preds):.2f}\")\n",
    "print(f\"MAE (Mean Absolute Error): {mean_absolute_error(y_test, y_preds):.2f}\")\n",
    "print(f\"MSE (Mean Squared Error): {mean_squared_error(y_test, y_preds):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a6bbce-8958-4ded-a307-e83ae1d1ba4d",
   "metadata": {},
   "source": [
    "## Improving A Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b11ade2-a622-4f6c-8630-9e00c2771b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c906fa-ef1a-416f-ad46-166153033e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c5a70d-a08b-4496-88a6-62e46daa1a3a",
   "metadata": {},
   "source": [
    "Improving a machine learning model involves several steps, including data preprocessing, hyperparameter tuning, feature engineering, and evaluating performance. Below is a **complete workflow** for improving a machine learning model using a regression problem (e.g., predicting house prices). This code uses the **Random Forest Regressor** as an example.\n",
    "\n",
    "---\n",
    "\n",
    "### Complete Code to Build and Improve a Regression Model\n",
    "\n",
    "```python\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load dataset (replace 'housing.csv' with your dataset file)\n",
    "housing_df = pd.read_csv('housing.csv')\n",
    "\n",
    "# Display first few rows of the dataset to verify it loaded correctly\n",
    "print(housing_df.head())\n",
    "\n",
    "# Check for missing values\n",
    "if housing_df.isnull().sum().sum() > 0:\n",
    "    # Fill missing values (e.g., using median)\n",
    "    housing_df = housing_df.fillna(housing_df.median())\n",
    "    print(\"Missing values filled.\")\n",
    "\n",
    "# Create features (X) and target (y)\n",
    "X = housing_df.drop(\"target\", axis=1)  # Replace \"target\" with the actual target column name\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features for better performance\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the model\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Perform hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='r2',\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the GridSearchCV to the training data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best model after hyperparameter tuning\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_preds = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nRegression Metrics on the Test Set:\")\n",
    "print(f\"R2 Score: {r2_score(y_test, y_preds):.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mean_absolute_error(y_test, y_preds):.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mean_squared_error(y_test, y_preds):.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {np.sqrt(mean_squared_error(y_test, y_preds)):.2f}\")\n",
    "\n",
    "# Feature importance (optional analysis)\n",
    "feature_importances = pd.DataFrame(\n",
    "    best_model.feature_importances_,\n",
    "    index=X.columns,\n",
    "    columns=[\"Importance\"]\n",
    ").sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importances:\")\n",
    "print(feature_importances)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Steps Explained:\n",
    "\n",
    "1. **Dataset Loading**:\n",
    "   - Load the dataset into a Pandas DataFrame and ensure it’s in the correct format.\n",
    "\n",
    "2. **Data Cleaning**:\n",
    "   - Check for missing values and handle them (e.g., using `median` imputation).\n",
    "   - Ensure there are no inconsistencies or outliers that can harm model performance.\n",
    "\n",
    "3. **Feature Scaling**:\n",
    "   - Scale features using `StandardScaler` to normalize numerical data for optimal model performance.\n",
    "\n",
    "4. **Hyperparameter Tuning**:\n",
    "   - Use `GridSearchCV` to find the best combination of hyperparameters for the Random Forest Regressor.\n",
    "\n",
    "5. **Evaluation Metrics**:\n",
    "   - Evaluate the model using metrics like **R2 score**, **MAE**, **MSE**, and **RMSE** to assess performance.\n",
    "\n",
    "6. **Feature Importance Analysis**:\n",
    "   - Analyze which features are contributing the most to the predictions, useful for understanding the model.\n",
    "\n",
    "---\n",
    "\n",
    "### Output Example:\n",
    "```\n",
    "Best Parameters: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
    "Regression Metrics on the Test Set:\n",
    "R2 Score: 0.85\n",
    "Mean Absolute Error (MAE): 2.34\n",
    "Mean Squared Error (MSE): 8.54\n",
    "Root Mean Squared Error (RMSE): 2.92\n",
    "\n",
    "Feature Importances:\n",
    "                Importance\n",
    "feature_1          0.35\n",
    "feature_2          0.25\n",
    "feature_3          0.15\n",
    "...\n",
    "```\n",
    "\n",
    "### What You Need:\n",
    "1. Replace `housing.csv` with your dataset.\n",
    "2. Ensure the target variable and feature columns are correctly named.\n",
    "3. Adjust hyperparameter ranges in `param_grid` based on your use case.\n",
    "\n",
    "Let me know if you’d like help with specific parts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682589e1-22e6-4274-8bf5-f33b8b0ed337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load dataset (replace 'housing.csv' with your dataset file)\n",
    "housing_df = pd.read_csv('housing.csv')\n",
    "\n",
    "# Display first few rows of the dataset to verify it loaded correctly\n",
    "print(housing_df.head())\n",
    "\n",
    "# Check for missing values\n",
    "if housing_df.isnull().sum().sum() > 0:\n",
    "    # Fill missing values (e.g., using median)\n",
    "    housing_df = housing_df.fillna(housing_df.median())\n",
    "    print(\"Missing values filled.\")\n",
    "\n",
    "# Create features (X) and target (y)\n",
    "X = housing_df.drop(\"target\", axis=1)  # Replace \"target\" with the actual target column name\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features for better performance\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the model\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Perform hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='r2',\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the GridSearchCV to the training data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best model after hyperparameter tuning\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_preds = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nRegression Metrics on the Test Set:\")\n",
    "print(f\"R2 Score: {r2_score(y_test, y_preds):.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mean_absolute_error(y_test, y_preds):.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mean_squared_error(y_test, y_preds):.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {np.sqrt(mean_squared_error(y_test, y_preds)):.2f}\")\n",
    "\n",
    "# Feature importance (optional analysis)\n",
    "feature_importances = pd.DataFrame(\n",
    "    best_model.feature_importances_,\n",
    "    index=X.columns,\n",
    "    columns=[\"Importance\"]\n",
    ").sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importances:\")\n",
    "print(feature_importances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36961e83-c4fa-4b08-a104-58c7a47f6b2a",
   "metadata": {},
   "source": [
    "## Tuning Hyperparameteres\n",
    "Let's make 3 sets, training, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5680de04-a7a3-4c67-bcc0-10d477ca240a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f179b898-6b33-4da5-8e81-2a6ee4012481",
   "metadata": {},
   "source": [
    "We are going to try and adjust:\n",
    "1. max_depth\n",
    "2. max_features\n",
    "3. min_samples_leaf\n",
    "4. min_samples_split\n",
    "5. n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0a924e-b781-43fb-9d07-b12ca43281a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preds(y_true, y_preds):\n",
    "    \"\"\"\n",
    "    Performs evaluation comparision on y_true labels vs. y_pred labels on a classification\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_preds)\n",
    "    precision = precision_score(y_true, y_preds)\n",
    "    recall = recall_score(y_true,y_preds)\n",
    "    f1 = f1__score(y_true, y_preds)\n",
    "    metric_dict = {\"accuracy\": round(accuracy, 2),\n",
    "                  \"precision\": round(precision, 2),\n",
    "                  \"recall\": round(recall, 2),\n",
    "                  \"f1\": round(f1, 2)}\n",
    "    print(f\"Acc: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Precision: {Precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 score: {f1:.2f}\")\n",
    "\n",
    "\n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0868e1f-a9d7-44fa-b4c6-80078d292317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    " \n",
    "# Shuffle the data \n",
    "\n",
    "heart_disease_shuffled = heart_disease.sample(frac=1)\n",
    "\n",
    "# Split into x and y\n",
    "\n",
    "x = heart_disease_shuffled.drop('target', axis = 1)\n",
    "y = heart_disease_shuffled[\"target\"]\n",
    "\n",
    "# Split teh data into train, validation and test sts \n",
    "\n",
    "train_split = round(0.7 * len(heart_disease_shuffled))  # 70% of data \n",
    "valid_split = round(train_split + 0.15 * len(heart_disease_shuffled)) # 15 % of data\n",
    "x_train, y_train = x[:train_split], y[:train_split]\n",
    "x_valid, y_valid = x[train_split: valid_split], y[train_split: valid_split]\n",
    "\n",
    "x_test, y_test = x[valid_split:], y[:valid_split]\n",
    "\n",
    "# len(x_train), len(x_valid), len(x_test)\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# Make Predictions \n",
    "y_preds = clf.predict(x_valid)\n",
    "\n",
    "# Evaluate the classifier on validation\n",
    "baseline_metrics = evaluate_preds(y_valid, y_preds)\n",
    "baseline_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "297da708-00b5-4753-84fa-a36c1e2cf80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 212, Validation: 45, Test: 46\n",
      "Baseline Metrics: {'accuracy': 0.8222222222222222, 'precision': np.float64(0.84), 'recall': np.float64(0.84), 'f1': np.float64(0.84)}\n"
     ]
    }
   ],
   "source": [
    " from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Shuffle the data (assuming heart_disease is a DataFrame)\n",
    "heart_disease_shuffled = heart_disease.sample(frac=1, random_state=42)\n",
    "\n",
    "# Split into features (X) and target (y)\n",
    "X = heart_disease_shuffled.drop('target', axis=1)\n",
    "y = heart_disease_shuffled['target']\n",
    "\n",
    "# Define split sizes\n",
    "train_split = round(0.7 * len(heart_disease_shuffled))  # 70% for training\n",
    "valid_split = round(train_split + 0.15 * len(heart_disease_shuffled))  # 15% for validation\n",
    "\n",
    "# Split the data\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_valid, y_valid = X[train_split:valid_split], y[train_split:valid_split]\n",
    "X_test, y_test = X[valid_split:], y[valid_split:]\n",
    "\n",
    "# Check the lengths of the splits\n",
    "print(f\"Train: {len(X_train)}, Validation: {len(X_valid)}, Test: {len(X_test)}\")\n",
    "\n",
    "# Create and fit the RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_preds = clf.predict(X_valid)\n",
    "\n",
    "# Define the evaluation function\n",
    "def evaluate_preds(y_true, y_preds):\n",
    "    accuracy = accuracy_score(y_true, y_preds)\n",
    "    precision = precision_score(y_true, y_preds)\n",
    "    recall = recall_score(y_true, y_preds)\n",
    "    f1 = f1_score(y_true, y_preds)\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "# Evaluate the classifier on the validation set\n",
    "baseline_metrics = evaluate_preds(y_valid, y_preds)\n",
    "print(\"Baseline Metrics:\", baseline_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c834835-3754-453c-b470-f9a470a02dad",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ad4facac-7115-4726-b3b6-c0fd4ec2e69b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 5) (666054482.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[59], line 5\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"max_features\": [\"auto\", \"sqrt\"]'\u001b[0m\n\u001b[1;37m                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "grid = {\"n_estimators\": (10, 100, 200, 500, 1000, 1200),\n",
    "                         \"max_depth\":[None, 5, 10, 20, 30],\n",
    "                          \"max_features\": [\"auto\", \"sqrt\"]'\n",
    "                          \"min_samples_split\": [2, 4, 6],\n",
    "                           \"min_samples_leaf\": [1, 2, 4]}\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split into x and y\n",
    "\n",
    "x = heart_disease_shuffled.drop('target', axis=1)\n",
    "y = heart_disease_shuffled[\"target\"]\n",
    "\n",
    "# Split into train & test sets\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
    "\n",
    "# Instantiate RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=1)\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "\n",
    "rs_clf = RandomizedSearchCV(estimator=clf,\n",
    "                           param_distributions=grid,\n",
    "                           n_iter=10, #  number of models to try\n",
    "                           cv=5, \n",
    "                           verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b05bdc-44e3-4098-8593-f242d53fabde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "grid = {\n",
    "    \"n_estimators\": [10, 100, 200, 500, 1000, 1200],\n",
    "    \"max_depth\": [None, 5, 10, 20, 30],\n",
    "    \"max_features\": [\"auto\", \"sqrt\"],\n",
    "    \"min_samples_split\": [2, 4, 6],\n",
    "    \"min_samples_leaf\": [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split into features (X) and target (y)\n",
    "X = heart_disease_shuffled.drop('target', axis=1)\n",
    "y = heart_disease_shuffled[\"target\"]\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate the RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_jobs=1, random_state=42)\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "rs_clf = RandomizedSearchCV(\n",
    "    estimator=clf,\n",
    "    param_distributions=grid,\n",
    "    n_iter=10,  # Number of models to try\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the RandomizedSearchCV\n",
    "rs_clf.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", rs_clf.best_params_)\n",
    "print(\"Best Score:\", rs_clf.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6edc192-b231-4455-b926-4332a2008ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", rs_clf.best_params_)  # Fixed the typo\n",
    "print(\"Best Score:\", rs_clf.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed3240b-5055-461e-ab01-df358391b44f",
   "metadata": {},
   "source": [
    "## Saving and Loading trained ML models\n",
    "Two ways to save and load ML models:\n",
    "1. With python's 'pickle' module\n",
    "2. with the 'joblib' module\n",
    "\n",
    "**Pickle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6740bf-aae2-4940-83dc-42f555f534fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save an existing model to file \n",
    "\n",
    "pickle.dump(gs_clf, open(\"gs_random_random_forest_model_1.pkl\", wb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a5ece2-7107-4f34-865d-ae0d872f0d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a saved model\n",
    "\n",
    "loades_pickle_model = pickle.load(\"open(gs_random_random_forest_model_1.pkl\"), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b09f4a7-5bf4-4665-b212-aa936433bc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some Predictions\n",
    "\n",
    "pickle_y_preds = loaded_pickle_model.predict(x_test)\n",
    "evaluate_preds(y_test, pickle_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc38ae7-34f4-4959-96a1-184adc9f760c",
   "metadata": {},
   "source": [
    "## with the 'joblib' module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ab1b5b2a-d65a-4ad0-bfb6-02687c22da59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n",
      "Model loaded successfully!\n",
      "Accuracy of the loaded model: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Save the model using joblib\n",
    "joblib.dump(clf, \"random_forest_model.joblib\")\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = joblib.load(\"random_forest_model.joblib\")\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Test the loaded model\n",
    "accuracy = loaded_model.score(X_test, y_test)\n",
    "print(f\"Accuracy of the loaded model: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07d0dc4-54d3-4836-996a-2ea016b2e4a8",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e1728e8c-f4ca-417f-bd0e-43dce31f389f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14043.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Black</td>\n",
       "      <td>35820.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32042.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>155144.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5716.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>66604.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>215883.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>248360.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12732.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Make Colour  Odometer (KM)  Doors    Price\n",
       "0     Honda  White        35431.0    4.0  15323.0\n",
       "1       BMW   Blue       192714.0    5.0  19943.0\n",
       "2     Honda  White        84714.0    4.0  28343.0\n",
       "3    Toyota  White       154365.0    4.0  13434.0\n",
       "4    Nissan   Blue       181577.0    3.0  14043.0\n",
       "..      ...    ...            ...    ...      ...\n",
       "995  Toyota  Black        35820.0    4.0  32042.0\n",
       "996     NaN  White       155144.0    3.0   5716.0\n",
       "997  Nissan   Blue        66604.0    4.0  31570.0\n",
       "998   Honda  White       215883.0    4.0   4001.0\n",
       "999  Toyota   Blue       248360.0    4.0  12732.0\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('car-sales-extended-missing-data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "93c29130-8225-4590-be39-6f41e6748a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make              object\n",
       "Colour            object\n",
       "Odometer (KM)    float64\n",
       "Doors            float64\n",
       "Price            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f8b0fe-5469-4727-a85b-e14b81cfa4b5",
   "metadata": {},
   "source": [
    "## Steps we want to do (All in one cell)\n",
    "1. Filll missing values\n",
    "2. Convert a model on the data\n",
    "3. Build a model on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "233a831f-adc5-43e7-abcc-c6c293bf8449",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'pipeline' from 'sklearn.pipeline' (C:\\Users\\jagda\\miniconda3\\Lib\\site-packages\\sklearn\\pipeline.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompose\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ColumnTransformer\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleImputer\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OneHotEncoder\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'pipeline' from 'sklearn.pipeline' (C:\\Users\\jagda\\miniconda3\\Lib\\site-packages\\sklearn\\pipeline.py)"
     ]
    }
   ],
   "source": [
    "# Getting Data Ready\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#Modelling\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "77b3cec2-582a-4d21-a89e-b76f43762201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0. An end-to-end Scikit-Learn workflow',\n",
       " '1. Getting the data ready',\n",
       " '2. Choose the right estimator/algorithm for our problems',\n",
       " '3. Fit the model/algorithm and use it to make predictions on our data',\n",
       " '4. Evaluating a model',\n",
       " '5. Improve a model',\n",
       " '6. Save and load a trained model',\n",
       " '7. Putting it all together!']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "what_were_covering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5418954f-f82d-480e-8bbb-1d6b35abe7cc",
   "metadata": {},
   "source": [
    "## Putting it all together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5bcc9a3b-0d7d-47bc-9366-940a4c8024ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14043.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Black</td>\n",
       "      <td>35820.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32042.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>155144.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5716.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>66604.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>215883.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>248360.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12732.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Make Colour  Odometer (KM)  Doors    Price\n",
       "0     Honda  White        35431.0    4.0  15323.0\n",
       "1       BMW   Blue       192714.0    5.0  19943.0\n",
       "2     Honda  White        84714.0    4.0  28343.0\n",
       "3    Toyota  White       154365.0    4.0  13434.0\n",
       "4    Nissan   Blue       181577.0    3.0  14043.0\n",
       "..      ...    ...            ...    ...      ...\n",
       "995  Toyota  Black        35820.0    4.0  32042.0\n",
       "996     NaN  White       155144.0    3.0   5716.0\n",
       "997  Nissan   Blue        66604.0    4.0  31570.0\n",
       "998   Honda  White       215883.0    4.0   4001.0\n",
       "999  Toyota   Blue       248360.0    4.0  12732.0\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('car-sales-extended-missing-data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b5bf42cc-d171-45bf-b4f8-d66c82f94f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make              object\n",
       "Colour            object\n",
       "Odometer (KM)    float64\n",
       "Doors            float64\n",
       "Price            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2682f374-c03d-4489-b301-6492710a249b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             49\n",
       "Colour           50\n",
       "Odometer (KM)    50\n",
       "Doors            50\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15942b80-87a4-40c0-a82e-d5c231d5f7e4",
   "metadata": {},
   "source": [
    " ## Steps we want to do (All in one cell)\n",
    "1. Fill missing values\n",
    "2. Convert a model on the data\n",
    "3. Build a model on the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "df55ec66-572c-429e-a42a-45605234655f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score: 0.22188417408787875\n"
     ]
    }
   ],
   "source": [
    "# Getting the data ready\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Modelling\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Setup Random Seed\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Import data and drop rows with missing labels\n",
    "data = pd.read_csv(\"car-sales-extended-missing-data.csv\")\n",
    "data.dropna(subset=[\"Price\"], inplace=True)\n",
    "\n",
    "# Define different features and transformer pipeline\n",
    "categorical_features = [\"Make\", \"Colour\"]\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "door_features = [\"Doors\"]  # Corrected: Renamed to `door_features` for consistency\n",
    "door_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=4))\n",
    "])\n",
    "\n",
    "numeric_features = [\"Odometer (KM)\"]\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\"))\n",
    "])\n",
    "\n",
    "# Combine all transformers into a single preprocessor using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "        (\"door\", door_transformer, door_features),  # Fixed typo `door_transformerm`\n",
    "        (\"num\", numeric_transformer, numeric_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Creating Preprocessing and Modelling Pipelines\n",
    "model = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", RandomForestRegressor())\n",
    "])\n",
    "\n",
    "# Split the data\n",
    "X = data.drop(\"Price\", axis=1)  # Fixed: Changed `x` to `X` for clarity\n",
    "y = data[\"Price\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Fit and score the model\n",
    "model.fit(X_train, y_train)  # Fixed: Changed `x_train, x_test` to `X_train, y_train`\n",
    "score = model.score(X_test, y_test)  # Fixed: Changed `x_test, y_test` to `X_test, y_test`\n",
    "\n",
    "# Print the score\n",
    "print(f\"Model Score: {score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70106ab-5a00-4841-85ed-b0d42c0332c7",
   "metadata": {},
   "source": [
    "The result of the `model.score` function is the **R² score (coefficient of determination)**. \n",
    "\n",
    "### **What is R² Score?**\n",
    "- It measures how well the predictions from the model match the actual target values.\n",
    "- The score ranges from **-∞ to 1**:\n",
    "  - **1**: Perfect prediction (model explains 100% of the variance in the target variable).\n",
    "  - **0**: Model performs as poorly as a baseline model that predicts the mean of the target variable.\n",
    "  - **Negative values**: The model performs worse than the baseline (e.g., it's worse than predicting the average for all data points).\n",
    "\n",
    "### **How to Interpret the Result?**\n",
    "1. **High Positive Value (close to 1)**:\n",
    "   - The model is good at predicting the target variable (`Price`) based on the given features.\n",
    "   - Most of the variability in the target is explained by the model.\n",
    "   \n",
    "2. **Value Close to 0**:\n",
    "   - The model is not effective in predicting the target variable.\n",
    "   - It performs similarly to simply predicting the average price for all cars.\n",
    "\n",
    "3. **Negative Value**:\n",
    "   - The model is performing worse than predicting the mean.\n",
    "   - Indicates that the model's predictions are very inaccurate or the model is poorly suited for the data.\n",
    "\n",
    "---\n",
    "\n",
    "### Example:\n",
    "If the result is:\n",
    "- **`Model Score: 0.85`**: \n",
    "  - The model explains **85%** of the variability in the car prices based on the features. This is a strong performance.\n",
    "  \n",
    "- **`Model Score: 0.15`**:\n",
    "  - The model only explains **15%** of the variability in car prices, indicating it isn't very effective.\n",
    "  \n",
    "- **`Model Score: -0.5`**:\n",
    "  - The model is worse than predicting the average price for all cars.\n",
    "\n",
    "---\n",
    "\n",
    "### **What Does the Score Represent in Your Code?**\n",
    "- This score evaluates the performance of the **Random Forest Regressor** on the test dataset (`X_test`, `y_test`).\n",
    "- It indicates how well the pipeline, including preprocessing and modeling, is at predicting car prices.\n",
    "\n",
    "Let me know the score you received, and we can analyze or improve it! 😊"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a11c0d-84dc-43cc-a54b-9671afdfd0f0",
   "metadata": {},
   "source": [
    "### Code Explanation\n",
    "\n",
    "The code demonstrates a complete machine learning pipeline using Python libraries to preprocess data, train a model, and evaluate its performance. Here's the breakdown:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Importing Libraries**\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import numpy as np\n",
    "```\n",
    "\n",
    "#### **Purpose**:\n",
    "- **`pandas`**: For loading and manipulating the dataset.\n",
    "- **`ColumnTransformer`**: Allows preprocessing of different types of data (e.g., categorical, numerical) in one pipeline.\n",
    "- **`Pipeline`**: Chains preprocessing and modeling steps together.\n",
    "- **`SimpleImputer`**: Handles missing values in the dataset by filling them with a specific value or statistical measure.\n",
    "- **`OneHotEncoder`**: Encodes categorical data as numeric arrays to use in machine learning models.\n",
    "- **`RandomForestRegressor`**: A machine learning model that performs regression using an ensemble of decision trees.\n",
    "- **`train_test_split`**: Splits the dataset into training and testing sets.\n",
    "- **`GridSearchCV`**: (Optional) For hyperparameter tuning, though it's not used here.\n",
    "- **`numpy`**: Provides numerical operations and is used here to set a random seed for reproducibility.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Loading and Cleaning Data**\n",
    "```python\n",
    "data = pd.read_csv(\"car-sales-extended-missing-data.csv\")\n",
    "data.dropna(subset=[\"Price\"], inplace=True)\n",
    "```\n",
    "\n",
    "#### **Purpose**:\n",
    "- **`pd.read_csv`**: Reads the dataset from a CSV file.\n",
    "- **`data.dropna`**: Removes rows where the target variable (`Price`) is missing because these rows cannot be used for model training.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Defining Preprocessing Pipelines**\n",
    "#### **Categorical Features**\n",
    "```python\n",
    "categorical_features = [\"Make\", \"Colour\"]\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "```\n",
    "\n",
    "- **Categorical Features**: Includes `Make` and `Colour`.\n",
    "- **Pipeline**:\n",
    "  1. **`SimpleImputer`**: Replaces missing values with the constant value `\"missing\"`.\n",
    "  2. **`OneHotEncoder`**: Converts categorical variables into numerical format using one-hot encoding.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Door Feature**\n",
    "```python\n",
    "door_features = [\"Doors\"]\n",
    "door_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=4))\n",
    "])\n",
    "```\n",
    "\n",
    "- **Door Feature**: Includes `Doors`.\n",
    "- **Pipeline**:\n",
    "  - **`SimpleImputer`**: Replaces missing values with the constant value `4`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Numerical Features**\n",
    "```python\n",
    "numeric_features = [\"Odometer (KM)\"]\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\"))\n",
    "])\n",
    "```\n",
    "\n",
    "- **Numerical Features**: Includes `Odometer (KM)`.\n",
    "- **Pipeline**:\n",
    "  - **`SimpleImputer`**: Replaces missing values with the mean value of the feature.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Combining Preprocessors**\n",
    "```python\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "        (\"door\", door_transformer, door_features),\n",
    "        (\"num\", numeric_transformer, numeric_features)\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "- **`ColumnTransformer`**: Combines the separate pipelines for categorical, door, and numerical features.\n",
    "  - **`\"cat\"`**: Applies the categorical transformer to `categorical_features`.\n",
    "  - **`\"door\"`**: Applies the door transformer to `door_features`.\n",
    "  - **`\"num\"`**: Applies the numeric transformer to `numeric_features`.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Building the Final Pipeline**\n",
    "```python\n",
    "model = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", RandomForestRegressor())\n",
    "])\n",
    "```\n",
    "\n",
    "- **Pipeline**:\n",
    "  1. **`preprocessor`**: Preprocesses the data using the combined transformations.\n",
    "  2. **`RandomForestRegressor`**: Fits the processed data to a machine learning model.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Splitting Data**\n",
    "```python\n",
    "X = data.drop(\"Price\", axis=1)\n",
    "y = data[\"Price\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "```\n",
    "\n",
    "- **`X`**: Feature data (all columns except `Price`).\n",
    "- **`y`**: Target variable (`Price`).\n",
    "- **`train_test_split`**:\n",
    "  - **Training Data**: 80% of the dataset for model training.\n",
    "  - **Testing Data**: 20% for evaluating model performance.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Training the Model**\n",
    "```python\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "- **`model.fit`**: Trains the `RandomForestRegressor` on the training data (`X_train`, `y_train`).\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Scoring the Model**\n",
    "```python\n",
    "score = model.score(X_test, y_test)\n",
    "print(f\"Model Score: {score}\")\n",
    "```\n",
    "\n",
    "- **`model.score`**: Evaluates the model on the test data (`X_test`, `y_test`) using the coefficient of determination (R² score).\n",
    "- **`print`**: Outputs the model's score.\n",
    "\n",
    "---\n",
    "\n",
    "### **Use of This Code**\n",
    "1. **Data Preprocessing**: Handles missing values and prepares categorical and numerical data for modeling.\n",
    "2. **Machine Learning Pipeline**: Combines preprocessing and modeling into a single object for simplicity and reproducibility.\n",
    "3. **Model Training and Evaluation**: Trains a regression model to predict car prices and evaluates its performance.\n",
    "\n",
    "This modular pipeline approach is ideal for automating repetitive preprocessing tasks and ensuring consistency in machine learning workflows. Let me know if you have more questions! 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dcd827-2288-4b4d-b864-cf5e99b3730c",
   "metadata": {},
   "source": [
    "## Use GridSearchCV with our regression Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "60461aee-f3c2-48c9-bcbc-a016b45df22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best Parameters: {'model__max_depth': 10, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 200}\n",
      "Best Score: 0.2994179773594382\n",
      "Test Set Score: 0.3152143197900892\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid for RandomForestRegressor\n",
    "param_grid = {\n",
    "    \"model__n_estimators\": [50, 100, 200],  # Number of trees in the forest\n",
    "    \"model__max_depth\": [None, 10, 20, 30],  # Maximum depth of the tree\n",
    "    \"model__min_samples_split\": [2, 5, 10],  # Minimum samples required to split an internal node\n",
    "    \"model__min_samples_leaf\": [1, 2, 4]    # Minimum samples required at a leaf node\n",
    "}\n",
    "\n",
    "# Wrap the pipeline with GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,               # Pipeline with preprocessor and RandomForestRegressor\n",
    "    param_grid=param_grid,         # Parameter grid\n",
    "    cv=5,                          # 5-fold cross-validation\n",
    "    scoring=\"r2\",                  # Optimize for R² score\n",
    "    verbose=2,                     # Print progress\n",
    "    n_jobs=-1                      # Use all available processors\n",
    ")\n",
    "\n",
    "# Fit the GridSearchCV to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print(\"Test Set Score:\", test_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869983b1-041a-4e2f-82d5-968e4ae11379",
   "metadata": {},
   "source": [
    "The values `Best Score: 0.2994179773594382` and `Test Set Score: 0.3152143197900892` represent the performance of your `RandomForestRegressor` model based on the **R² score** (coefficient of determination). Here’s what they mean in the context of your code:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Best Score (`0.2994`)**\n",
    "- **What it means**:  \n",
    "  This is the **mean cross-validation R² score** for the best combination of hyperparameters found during the `GridSearchCV` process.\n",
    "- **How it is calculated**:\n",
    "  - During `GridSearchCV`, the training dataset (`X_train`, `y_train`) is split into 5 folds.\n",
    "  - The model is trained and validated on different subsets of this data for each hyperparameter combination.\n",
    "  - The R² score is averaged across these 5 folds for each parameter combination.\n",
    "  - The highest mean R² score across all combinations is returned as the **Best Score**.\n",
    "\n",
    "- **Interpretation**:\n",
    "  - An R² score of `0.2994` indicates that the model explains about **29.94% of the variance** in the training data during cross-validation.\n",
    "  - This value seems low, meaning the model isn't capturing a lot of the variance in the data. It could be due to:\n",
    "    - Insufficient feature engineering.\n",
    "    - Missing important predictors.\n",
    "    - A need for hyperparameter tuning or using a different model.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Test Set Score (`0.3152`)**\n",
    "- **What it means**:  \n",
    "  This is the R² score when the best model (from `GridSearchCV`) is evaluated on the **unseen test data (`X_test`, `y_test`)**.\n",
    "- **How it is calculated**:\n",
    "  - The model is trained using the full training dataset (`X_train`, `y_train`) with the optimal hyperparameters.\n",
    "  - It is then evaluated on the test dataset (`X_test`, `y_test`) to calculate the R² score.\n",
    "\n",
    "- **Interpretation**:\n",
    "  - An R² score of `0.3152` indicates that the model explains about **31.52% of the variance** in the test data.\n",
    "  - This value being slightly higher than the cross-validation score suggests that the model generalizes better on unseen data compared to its performance during cross-validation.\n",
    "\n",
    "---\n",
    "\n",
    "### **Insights and Next Steps**\n",
    "- Both scores (`0.2994` and `0.3152`) indicate that your model is only explaining about 30% of the variance in the data. This suggests that there’s room for improvement in the model’s performance.\n",
    "  \n",
    "#### **Possible Improvements**:\n",
    "1. **Feature Engineering**:\n",
    "   - Explore and add more meaningful predictors (features) to the dataset.\n",
    "   - Investigate interactions between features or create derived features.\n",
    "  \n",
    "2. **Data Cleaning**:\n",
    "   - Look for issues like outliers or non-informative data points.\n",
    "   - Investigate if additional preprocessing steps (e.g., scaling, transformations) are necessary.\n",
    "\n",
    "3. **Hyperparameter Tuning**:\n",
    "   - Experiment with a wider range of hyperparameters in `GridSearchCV`.\n",
    "   - Try other models like Gradient Boosting, XGBoost, or LightGBM, which often perform better in regression tasks.\n",
    "\n",
    "4. **Check for Data Leakage**:\n",
    "   - Ensure that the test data (`X_test`, `y_test`) is completely unseen and not influencing the training process.\n",
    "\n",
    "5. **Gather More Data**:\n",
    "   - If possible, increase the dataset size to provide the model with more information.\n",
    "\n",
    "Would you like assistance implementing any of these improvements? 😊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0a266d-6f52-4779-8fd1-c16ee6d84477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bd142e-000b-47fd-a9eb-8af12dcab86f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae0b968-cbe2-4fbd-9f61-11d19ac7c028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54dd795-4c9f-4a9d-9d35-272b37914a26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db85dfe-dc50-46ac-a86f-db7c864be2d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3195ae28-b504-462e-aa03-ee1888dd36ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8012c3d7-f638-4226-89a3-cbf685b847fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449c5272-4eb1-4cf9-9a76-1eabf7bb1bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2fcb99-ad82-47e5-8f57-886ebdfe9e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e753afa-20f5-417f-9fe0-e53b5b452b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f808ed-982a-46d6-9091-af3405d52928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f489fbd8-781e-4a0a-bce4-7655ca0dd22e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb53f86-3cdf-4fe2-b29e-57463c48d3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aff356-bfd0-481c-9ad2-8db1ff0d58c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117ea5d4-cb40-40d1-9025-b939e06de426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a248f1e8-75d2-4345-86a3-8ebca7872b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5d0355-70af-4023-a88d-793eb36f2eea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e172bfb-2867-43c6-9400-3eedc072708e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed486f6-74e2-42a4-bfe2-7513f359abbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac6a162-2289-4f9e-948d-89a4ad423995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca9968a-256d-4ba3-82af-6d27c12eadf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a182582d-6d23-43ce-b36c-0e9d7725515d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0e23d3-f255-4aea-b16c-bd42f1a9ca2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a6146e-1b59-47de-af17-dee91e451c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b233625e-ffe2-4467-9a3a-286dbcd2a851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3791e2d-e7e3-4f61-a785-a6899d097fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001d776b-c765-4e69-be7f-e4cbc8506812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba6b463-2114-4efc-a00b-6ecc2e08f326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93823f7a-a887-4cae-bec8-d89f210897b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6784fd-8979-4de6-9fde-05a1b19ad340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689a0bda-b950-4751-9bcb-c0444f2c231c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d534e807-0416-4ea6-bd0e-c2b694db8376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c55cc2-223c-4994-9a89-4c25aa9c9ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b042c3-7b03-4724-8fcc-ef228b9ea23b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf563fa-dc29-4161-b23d-593da7f3436e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f1f6e3-4932-495d-8c50-f8f117cc6f30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6a63d4-80c8-4340-aeda-5110be3e6dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4ba450-fba9-43cb-8407-d86a2ef7556f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448be5e0-c2d0-4cbf-b85b-4b116cae5ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ad3323-f858-445f-86f5-eb9c7b46a227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b47511a-cb93-4acc-bd3f-e69b4076965d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369cfd7b-8569-4a23-9999-4c8decca6c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8deca476-1eef-45ef-999a-ea7281719ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0af6344-8d03-49c3-b1ea-55fa051e2421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6952fda4-602e-4aae-84d3-d9f2bb202128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f73fad-1afc-4d0a-97ec-9c5872b80bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce081005-0a5f-443e-927e-feadeee144a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6248deeb-90dd-4c31-9ab0-1f621b6c04a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9d0ff3-778a-4dbc-af53-65dce517bad5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f200e97-ed5e-48aa-b890-d0f2ad287f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3328a428-13a7-4961-919b-99fedcadf90a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1cd94a-e3e3-447e-b866-3d13c0d73c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71bb0fa-d6fb-4a1f-a604-3ca1e8e3445e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0bb006-ab0b-4bc0-8d86-eb34a3935ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4395f56-f749-461e-b7c7-c448b61c459f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34caf24-7444-4673-bd7a-dac15c84bbef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4aa057-b90e-4c0d-ac84-2c2fb9471d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69757bd-1746-4f89-b56c-85dc14639c01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df98b8f-36c7-420c-9ce3-6489bf0f7c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4458a784-8158-475a-a58a-4920b5e90c0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19d4946-b7c5-43df-ba8a-b9847d8c3e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28c298a-c954-442f-b562-8b450358fe3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa71ae9-2924-4a46-8c95-8fc51fb71c45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc80764-3c42-46a2-9a15-b3bfdb57b015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843b8ef1-0cad-438f-88e7-9a96cc53d91a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1389a87-cfd2-434c-805d-8fd22c45ee30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7374b2-c905-499c-9591-d55d3aef8d54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e334ec24-839c-438c-be51-364061d4feca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a10238-913e-4116-80eb-966d687a1ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfa1859-400e-412e-92c6-7dca12e631b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c3ee92-eaa7-47d5-9529-9affd22457ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8a9ee8-afb9-41d2-a849-a3f9f752c33b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eaa5f0-2e9b-42d8-932d-8acad1a78989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494f3510-5286-4894-96ef-f846e7c1a1ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3]",
   "language": "python",
   "name": "conda-env-miniconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
